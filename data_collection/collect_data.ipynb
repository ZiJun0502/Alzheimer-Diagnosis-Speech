{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\zijun0502\\Codes\\Python\\ML_Final\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import noisereduce as nr\n",
    "from pydub.utils import mediainfo\n",
    "from scipy.io import wavfile\n",
    "import csv\n",
    "import threading\n",
    "import queue\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_time_stamp(time_stamp):\n",
    "    return sum(end_time - start_time for start_time, end_time in time_stamp)\n",
    "        \n",
    "def get_timestamp(file_path) -> list[tuple[int, int]]: \n",
    "    pattern = r'\\d+_\\d'\n",
    "    par_intervals = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        par_speaking = False\n",
    "        interval = [] # [start, end]\n",
    "        for line in file:\n",
    "            if line.startswith(\"*PAR:\"):\n",
    "                par_speaking = True\n",
    "            elif line.startswith(\"%\"):\n",
    "                par_speaking = False\n",
    "            elif line.startswith(\"*INV:\") or line.startswith(\"*OTH:\"):\n",
    "                if interval and interval[1] - interval[0] > 3000:\n",
    "                    par_intervals.append(interval)\n",
    "                interval = []\n",
    "                get_timestr = '' \n",
    "            if par_speaking == True:\n",
    "                get_timestr = line.split()[-1][1:-1]\n",
    "                if(re.match(pattern, get_timestr) is not None):\n",
    "                    if not interval:\n",
    "                        interval = list(map(int, get_timestr.split('_')))\n",
    "                    else:\n",
    "                        temp_interval = list(map(int, get_timestr.split('_')))\n",
    "                        interval[1] = temp_interval[1]\n",
    "        if interval:\n",
    "            par_intervals.append(interval)\n",
    "\n",
    "\n",
    "    return par_intervals\n",
    "def get_patient_info(file_path) -> str:\n",
    "    with open(file_path, 'r') as file:\n",
    "        timestr = ''\n",
    "        for line in file:\n",
    "            if line.startswith(\"@ID:\"):\n",
    "                temp = line.split()[1].split('|')\n",
    "                for st in temp:\n",
    "                    if st == \"PAR\":\n",
    "                        return [s for s in temp if s != \"\"]\n",
    "            \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment, effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedAudioSegment:\n",
    "    def __init__(self, name, info, timestamp, audio_segment):\n",
    "        self.name = name\n",
    "        self.info = info\n",
    "        self.timestamp = timestamp\n",
    "        self.audio_segment = audio_segment\n",
    "\n",
    "def load_file(file_path):\n",
    "    \"\"\"\n",
    "    Create AudioSegment object from a path.\n",
    "    \"\"\"\n",
    "    aud = AudioSegment.from_file(file_path, format=\"mp3\")\n",
    "\n",
    "    parent_path = os.path.dirname(file_path)\n",
    "    name = file_path.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "    cha_file_path = os.path.join(parent_path, name + '.cha')\n",
    "    timestamp = get_timestamp(cha_file_path)\n",
    "    info = get_patient_info(cha_file_path)\n",
    "    \n",
    "    return NamedAudioSegment(name, info, timestamp, aud)\n",
    "def normalize_audio(audio, target_dBFS = -20):\n",
    "    \"\"\"\n",
    "    Normalize all audio to -20 dBFS\n",
    "    \"\"\"\n",
    "    change_in_dBFS = target_dBFS - audio.dBFS\n",
    "    normalized_audio = audio + change_in_dBFS\n",
    "\n",
    "    return normalized_audio\n",
    "def average_channels(audio):\n",
    "    \"\"\"\n",
    "    If an audio file has multiple channels,\n",
    "    combine them into one channel by averaging all channels\n",
    "    \"\"\"\n",
    "    # Split the multi-channel audio into individual channels\n",
    "    channels = audio.split_to_mono()\n",
    "    # Combine channels by averaging\n",
    "    combined_audio = channels[0]\n",
    "\n",
    "    for audio in channels[1::]:\n",
    "        combined_audio = combined_audio.overlay(audio)\n",
    "\n",
    "    return combined_audio\n",
    "\n",
    "def get_labels(infos):\n",
    "    \"\"\"\n",
    "    Get labels, with alzeheimer's as 1 and MCI as 0.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    MCI = [\"mci\"]\n",
    "    AD = [\"alzheimer\", \"ad\", \"alzheimer's\", \"possiblead\", \"probablead\"]\n",
    "    MCI_LABEL = 0\n",
    "    AD_LABEL = 1\n",
    "    NONE_LABEL = 0\n",
    "    for info in infos:\n",
    "        info = info.lower().split()\n",
    "        found = False\n",
    "        for t in info:\n",
    "            if t.lower() in MCI:\n",
    "                found = True\n",
    "                labels.append(MCI_LABEL)\n",
    "            elif t.lower() in AD:\n",
    "                found = True\n",
    "                labels.append(AD_LABEL)\n",
    "        if not found:\n",
    "            labels.append(NONE_LABEL)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "data_folder = os.path.join(current_directory, 'data')\n",
    "infos = []\n",
    "names = []\n",
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "output_directory = os.path.join(current_directory,\"Audio_Output\")\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "def open_raw_audio(filepath: str) -> NamedAudioSegment:\n",
    "    return load_file(filepath)\n",
    "\n",
    "def segmentize(named_audio_segment: NamedAudioSegment) -> list[AudioSegment, str]:\n",
    "    # This function should take a NamedAudioSegment object and return an AudioSegment object\n",
    "    print(f\"Processing {named_audio_segment.name}\"\n",
    "    , flush=True)\n",
    "        \n",
    "    if get_length_time_stamp(named_audio_segment.timestamp) < 10000:\n",
    "        return \n",
    "    # audio output path\n",
    "    # combined_seg_path = os.path.join(combined_directory, f\"{named_audio_segment.name}.wav\")\n",
    "    # create output folder\n",
    "    # seg_output_directory = os.path.join(aud_segments_directory, named_audio_segment.name)\n",
    "    # os.makedirs(seg_output_directory, exist_ok=True)\n",
    "    \n",
    "    infos.append(' '.join(named_audio_segment.info[1::]))\n",
    "    names.append(named_audio_segment.name)\n",
    "    \n",
    "    \n",
    "    combined_audio = AudioSegment.empty()\n",
    "    for i, (start, end) in enumerate(named_audio_segment.timestamp):\n",
    "        seg = named_audio_segment.audio_segment[max(0, start-20) : min(len(named_audio_segment.audio_segment), end+20)]\n",
    "        if len(seg) > 2000:\n",
    "            seg = average_channels(seg)\n",
    "            samples = seg.get_array_of_samples()\n",
    "            rate = seg.frame_rate\n",
    "            reduced_aud = nr.reduce_noise(y=samples, sr=rate)\n",
    "            seg = effects.normalize(seg._spawn(reduced_aud))\n",
    "            seg = normalize_audio(seg)\n",
    "            combined_audio += seg\n",
    "    return combined_audio, named_audio_segment.name\n",
    "\n",
    "def write_audio(audio_segment: list[AudioSegment, str]) -> None:\n",
    "    file_path = os.path.join(output_directory, audio_segment[1])\n",
    "    audio_segment[0].export(output_directory + f\"\\\\{audio_segment[1]}.wav\", format=\"wav\")\n",
    "    return\n",
    "\n",
    "def worker_function(worker_id, input_queue, output_queue, stage_function):\n",
    "    while True:\n",
    "        item = input_queue.get()\n",
    "        if item is None:\n",
    "            if output_queue:\n",
    "                output_queue.put(None)\n",
    "            break\n",
    "        result = stage_function(item)\n",
    "        if output_queue and result:\n",
    "            output_queue.put(result)\n",
    "\n",
    "def main():\n",
    "    num_threads = 8  # Adjust this based on your system and workload\n",
    "    open_pool = queue.Queue()\n",
    "    segmentize_pool = queue.Queue()\n",
    "    write_pool = queue.Queue()\n",
    "\n",
    "    # Create and start threads for each stage\n",
    "    open_threads = [threading.Thread(target=worker_function, args=(i, open_pool, segmentize_pool, open_raw_audio)) for i in range(num_threads)]\n",
    "    segmentize_threads = [threading.Thread(target=worker_function, args=(i, segmentize_pool, write_pool, segmentize)) for i in range(num_threads)]\n",
    "    write_threads = [threading.Thread(target=worker_function, args=(i, write_pool, None, write_audio)) for i in range(num_threads)]\n",
    "\n",
    "    # Enqueue the initial task for the first stage\n",
    "    mp3_file_paths = [os.path.join(data_folder, file) for file in os.listdir(data_folder) if file.lower().endswith(\".mp3\") or file.lower().endswith(\".wav\")]\n",
    "    for path in mp3_file_paths:\n",
    "        open_pool.put(path)\n",
    "        \n",
    "    # Signal the write threads to exit\n",
    "    for _ in range(num_threads):\n",
    "        open_pool.put(None)\n",
    "    for thread in open_threads + segmentize_threads + write_threads:\n",
    "        thread.start()\n",
    "    # Wait for all threads to finish\n",
    "    for thread in open_threads + segmentize_threads + write_threads:\n",
    "        thread.join()\n",
    "\n",
    "    # print(\"Waiting for writing threads to join\")\n",
    "    # Wait for write threads to finish\n",
    "    # for thread in write_threads:\n",
    "    #     thread.join()\n",
    "\n",
    "    print(\"Writing csv\")\n",
    "    labels = get_labels(infos)\n",
    "    csv_file_name = \"patient_info.csv\"\n",
    "    with open(os.path.join(output_directory, csv_file_name), 'w', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "        csv_writer.writerow([\"name\", \"label\", \"infos\"])\n",
    "\n",
    "        # Write the data from the lists\n",
    "        csv_writer.writerows(list(zip(names, labels, infos)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Baycrest2103\n",
      "Processing Baycrest12814\n",
      "Processing Baycrest7352\n",
      "Processing Baycrest11633\n",
      "Processing Baycrest11976\n",
      "Processing Baycrest12813\n",
      "Processing Baycrest12257\n",
      "Processing Baycrest8538\n",
      "Processing Baycrest11634\n",
      "Processing Baycrest8961\n",
      "Writing csv\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
