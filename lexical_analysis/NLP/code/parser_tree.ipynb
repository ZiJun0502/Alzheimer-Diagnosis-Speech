{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8AWLrYh-1uJ"
      },
      "outputs": [],
      "source": [
        "# Install stanza; note that the prefix \"!\" is not needed if you are running in a terminal\n",
        "!pip install stanza\n",
        "\n",
        "# Import stanza\n",
        "import stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXQaevZe_B-D",
        "outputId": "75b5ad00-8d53-46a9-f7f0-267864e53775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:stanza:Directory ./corenlp already exists. Please install CoreNLP to a new directory.\n"
          ]
        }
      ],
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = './corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)\n",
        "\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qk6WM4m_G_h"
      },
      "outputs": [],
      "source": [
        "# Examine the CoreNLP installation folder to make sure the installation is successful\n",
        "!ls $CORENLP_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVpja4D7_KGS"
      },
      "outputs": [],
      "source": [
        "# Import client module\n",
        "from stanza.server import CoreNLPClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm6irQB9_MGs"
      },
      "outputs": [],
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(\n",
        "    annotators=['tokenize', 'ssplit', 'pos', 'lemma'],\n",
        "    memory='1000T',\n",
        "    timeout=1e32,\n",
        "    endpoint='http://localhost:4015',\n",
        "    max_char_length=1e24,\n",
        "    thread=100,\n",
        "    be_quiet=True)\n",
        "print(client)\n",
        "\n",
        "# Start the background server and wait for some time\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
        "client.start()\n",
        "import time; time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AOoBJrP_Oub"
      },
      "outputs": [],
      "source": [
        "# Print background processes and look for java\n",
        "# You should be able to see a StanfordCoreNLPServer java process running in the background\n",
        "!ps -o pid,cmd | grep java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH3KPBHiywfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98203e39-4f2d-43d0-980b-6d21768ebbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import csv\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6PBu5ZIzFAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fd0ffd-60c9-4e2b-a97d-623bdf7dc88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AaronHuey_2010X.sph', 'AdamGrosser_2007.sph', 'AdamSadowsky_2010X.sph', 'AdamSavage_2008P.sph', 'AditiShankardass_2009I.sph', 'AdoraSvitak_2010.sph', 'AimeeMullins_1998.sph', 'AimeeMullins_2009U.sph', 'AJJacobs_2007P.sph', 'AlaindeBotton_2009G.sph', 'AlanKay_2007.sph', 'AlanRussell_2006.sph', 'AlanSiegel_2010.sph', 'AlexisOhanian_2009I.sph', 'AlexTabarrok_2009.sph', 'AlGore_2006.sph', 'AlGore_2008.sph', 'AliCarrChellman_2010X.sph', 'AlisonJackson_2005G.sph', 'AllisonHunt_2007.sph', 'AlSeckel_2004.sph', 'AndersYnnerman_2010X.sph', 'AndrewMwenda_2007G.sph', 'AnilGupta_2009I.sph', 'AnnaDeavereSmith_2005.sph', 'AnthonyAtala_2009P.sph', 'AnupamMishra_2009I.sph', 'AriannaHuffington_2010W.sph', 'ArthurBenjamin_2005.sph', 'ArthurBenjamin_2009.sph', 'ArthurGanson_2004.sph', 'ArthurPottsDawson_2010G.sph', 'AsherHasan_2009I.sph', 'AshrafGhani_2005G.sph', 'AubreydeGrey_2005G.sph', 'AuretvanHeerden_2010G.sph', 'BarbaraBlock_2010Z.sph', 'BarrySchuler_2008P.sph', 'BarrySchwartz_2009.sph', 'BarrySchwartz_2010S.sph', 'BartonSeaver_2010Z.sph', 'BartWeetjens_2010X.sph', 'BeauLotto_2009G.sph', 'BeckyBlanton_2009G.sph', 'BenCameron_2010X.sph', 'BenDunlap_2007.sph', 'BenjaminWallace_2008P.sph', 'BenjaminZander_2008.sph', 'BenKatchor_2002.sph', 'BenoitMandelbrot_2010.sph', 'BenSaunders_2005.sph', 'BertrandPiccard_2009G.sph', 'BeverlyJoubertandDereckJoubert_2010W.sph', 'BillClinton_2007.sph', 'BillDavenhall_2009P.sph', 'BillGates_2009.sph', 'BillGross_2003.sph', 'BillJoy_2006.sph', 'BillStone_2007.sph', 'BillStrickland_2002.sph', 'BillyGraham_1998.sph', 'BirkeBaehr_2010X.sph', 'BjarkeIngels_2009G.sph', 'BjornLomborg_2005.sph', 'BlaiseAguerayArcas_2010.sph', 'BobThurman_2006S.sph', 'BonnieBassler_2009.sph', 'Bono_2005.sph', 'BrendaLaurel_1998.sph', 'BreneBrown_2010X.sph', 'BrewsterKahle_2007P.sph', 'BrianCox_2008.sph', 'BrianCox_2010S.sph', 'BrianGreene_2005.sph', 'BrianSkerry_2010Z.sph', 'BruceBuenodeMesquita_2009.sph', 'BruceFeiler_2010P.sph', 'BruceMcCall_2008P.sph', 'BrunoBowden_2008.sph', 'BurtRutan_2006.sph', 'CalebChung_2007P.sph', 'CameronHerold_2009X.sph', 'CameronSinclair_2006.sph', 'CameronSinclair_2009G.sph', 'CarlHonore_2005G.sph', 'CarlSafina_2010X.sph', 'CarmenAgraDeedy_2005.sph', 'CarneRoss_2009P.sph', 'CarolineLavelleFARTHERTHANTHESUN_2005.sph', 'CarolinePhillips_2010G.sph', 'CarolynPorco_2007.sph', 'CarolynPorco_2009U.sph', 'CarolynSteel_2009G.sph', 'CarterEmmart_2010.sph', 'CaryFowler_2009G.sph', 'CatherineMohr_2009.sph', 'CatherineMohr_2010U.sph', 'CharityTillemannDick_2010P.sph', 'CharlesAnderson_2009I.sph', 'CharlesElachi_2008P.sph', 'CharlesFleischer_2005.sph', 'CharlesLeadbeater_2005G.sph', 'CharlesLeadbeater_2010S.sph', 'CharlesLimb_2010X.sph', 'CharlesMoore_2009U.sph', 'ChimamandaAdichie_2009G.sph', 'ChipConley_2010.sph', 'ChrisAbani_2007G.sph', 'ChrisAbani_2008.sph', 'ChrisAnderson_2002.sph', 'ChrisAnderson_2004.sph', 'ChrisAnderson_2010G.sph', 'ChrisBangle_2002.sph', 'ChrisJordan_2008.sph', 'ChristienMeindertsma_2010G.sph', 'ChristopherDeam_2002.sph', 'ChristopherdeCharms_2008.sph', 'ChristopherMcDougall_2010X.sph', 'ChristopherPoole_2010.sph', 'CKWilliams_2001.sph', 'ClayShirky_2005G.sph', 'ClayShirky_2009S.sph', 'ClayShirky_2010S.sph', 'CliffordStoll_2006.sph', 'ConradWolfram_2010G.sph', 'CorneilleEwango_2007G.sph', 'CraigVenter_2005G.sph', 'CraigVenter_2010P.sph', 'CynthiaSchneider_2009G.sph', 'DanAriely_2008P.sph', 'DanAriely_2009.sph', 'DanBarber_2008P.sph', 'DanBuettner_2009X.sph', 'DanCobley_2010G.sph', 'DanDennett_2002.sph', 'DanDennett_2003.sph', 'DanDennett_2006.sph', 'DanDennett_2009U.sph', 'DanGilbert_2004.sph', 'DanGilbert_2005G.sph', 'DanielGoleman_2007.sph', 'DanielKraft_2009.sph', 'DanielLibeskind_2009.sph', 'DanielPink_2009G.sph', 'DanMeyer_2010X.sph', 'DanPhillips_2010X.sph', 'DaveEggers_2008.sph', 'DavidAgus_2009P.sph', 'DavidBismark_2010G.sph', 'DavidBlaine_2009P.sph', 'DavidBolinsky_2007.sph', 'DavidByrne_2010.sph', 'DavidCameron_2010.sph', 'DavidCarson_2003.sph', 'DavidDeutsch_2005G.sph', 'DavidDeutsch_2009G.sph', 'DavidGallo_1998.sph', 'DavidGallo_2007.sph', 'DavidGriffin_2008.sph', 'DavidHanson_2009.sph', 'DavidHoffman_2007.sph', 'DavidHoffman_2008.sph', 'DavidHolt_2004.sph', 'DavidKeith_2007S.sph', 'DavidKelley_2002.sph', 'DavidLogan_2009.sph', 'DavidMacaulay_2002.sph', 'DavidMcCandless_2010G.sph', 'DavidPerry_2006.sph', 'DavidPogue_2006.sph', 'DavidPogue_2007.sph', 'DavidPogue_2008P.sph', 'DavidRockwell_2002.sph', 'DavidSRose_2007U.sph', 'DeanKamen_2002.sph', 'DeanKamen_2007.sph', 'DeanKamen_2009P.sph', 'DeanOrnish_2004.sph', 'DeanOrnish_2006.sph', 'DeanOrnish_2008.sph', 'DeborahGordon_2003.sph', 'DeborahRhodes_2010W.sph', 'DeborahScranton_2007.sph', 'DeeBoersma_2010Z.sph', 'DenisDutton_2010.sph', 'DennisHong_2009X.sph', 'DennisvanEngelsdorp_2008P.sph', 'DerekSivers_2009I.sph', 'DerekSivers_2010G.sph', 'DerekSivers_2010U.sph', 'DevduttPattanaik_2009I.sph', 'DianaLaufenberg_2010X.sph', 'DianeBenscoter_2009U.sph', 'DiannaCohen_2010Z.sph', 'DimitarSasselov_2010G.sph', 'DonNorman_2003.sph', 'DorisKearnsGoodwin_2008.sph', 'EamesDemetrios_2007.sph', 'EbenBayer_2010G.sph', 'EddiReaderWHATYOUDO_2004.sph', 'EdUlbrich_2009.sph', 'EdwardBurtynsky_2005.sph', 'EdwardBurtynsky_2009G.sph', 'EinsteinTheParrot_2006.sph', 'ElaineMorgan_2009G.sph', 'EleniGabreMadhin_2007G.sph', 'ElifShafak_2010G.sph', 'ElizabethLesser_2010W.sph', 'ElizabethPisani_2010.sph', 'EllenDunhamJones_2010X.sph', 'EllenGustafson_2010X.sph', 'EmilyLevine_2002.sph', 'EmilyOster_2007.sph', 'EmilyPilloton_2010G.sph', 'EmmanuelJal_2009G.sph', 'EnricSala_2010Z.sph', 'EOWilson_2007.sph', 'EricBerlow_2010G.sph', 'EricDishman_2009P.sph', 'EricGiler_2009G.sph', 'EricSanderson_2009G.sph', 'EricTopol_2009P.sph', 'ErikHersman_2009U.sph', 'ErinMcKean_2007.sph', 'ErnestMadu_2007G.sph', 'EstherDuflo_2010.sph', 'EthanZuckerman_2010G.sph', 'EuvinNaidoo_2007G.sph', 'EvanGrant_2009G.sph', 'EvanWilliams_2009.sph', 'EvaVertes_2005.sph', 'EvaZeisel_2001.sph', 'EveEnsler_2004.sph', 'EveEnsler_2005G.sph', 'EveEnsler_2009I.sph', 'EvelynGlennie_2003.sph', 'EvgenyMorozov_2009G.sph', 'EWidder_2010Z.sph', 'FabianHemmert_2009X.sph', 'FeisalAbdulRauf_2009P.sph', 'FelixDennis_2004.sph', 'FieldsWickerMiurin_2009S.sph', 'FrancoSacchi_2007G.sph', 'FrankGehry_1990.sph', 'FrankGehry_2002.sph', 'FransLanting_2005.sph', 'FrederickBalagadde_2010U.sph', 'FreemanDyson_2003.sph', 'GarikIsraelian_2009G.sph', 'GarrettLisi_2008.sph', 'GaryLauder_2010.sph', 'GaryWolf_2010S.sph', 'GeoffMulgan_2009G.sph', 'GeorgeAyittey_2007G.sph', 'GeorgeDyson_2002.sph', 'GeorgeDyson_2003.sph', 'GeorgeSmoot_2008P.sph', 'GeorgeWhitesides_2009X.sph', 'GeorgeWhitesides_2010.sph', 'GeroMiesenboeck_2010G.sph', 'GeverTulley_2007U.sph', 'GeverTulley_2009.sph', 'GolanLevin_2004.sph', 'GolanLevin_2009.sph', 'GordonBrown_2009G.sph', 'GrahamHawkes_2005.sph', 'GrahamHill_2010.sph', 'GregLynn_2005.sph', 'GregoryPetsko_2008.sph', 'GregoryStock_2003.sph', 'GregStone_2010Z.sph', 'Halla_Tomasdottir_2010W.sph', 'HannaRosin_2010W.sph', 'HansRosling_2006.sph', 'HansRosling_2007.sph', 'HansRosling_2009.sph', 'HansRosling_2009I.sph', 'HansRosling_2009S.sph', 'HansRosling_2010S.sph', 'HansRosling_2010X.sph', 'HarshaBhogle_2009I.sph', 'HeatherKnight_2010W.sph', 'HectorRuiz_2007G.sph', 'HelenFisher_2006.sph', 'HelenFisher_2008.sph', 'HeribertWatzke_2010G.sph', 'HillelCooperman_2010U.sph', 'HisHolinessTheKarmapa_2009I.sph', 'HodLipson_2007.sph', 'HowardRheingold_2005.sph', 'IanDunbar_2007P.sph', 'IanGoldin_2009G.sph', 'IngeMissmahl_2010G.sph', 'IqbalQuadir_2005G.sph', 'IrwinRedlener_2008.sph', 'IsaacMizrahi_2008.sph', 'IsabelAllende_2007.sph', 'ItayTalgam_2009G.sph', 'JacekUtko_2009.sph', 'JackieTabick_2009P.sph', 'JacquelineNovogratz_2005G.sph', 'JacquelineNovogratz_2007G.sph', 'JacquelineNovogratz_2009S.sph', 'JacquelineNovogratz_2009U.sph', 'JaimeLerner_2007.sph', 'JakeShimabukuro_2010.sph', 'JakobTrollback_2007.sph', 'JamaisCascio_2006.sph', 'JamesBalog_2009G.sph', 'JamesForbes_2009P.sph', 'JamesGeary_2009G.sph', 'JamesHowardKunstler_2004.sph', 'JamesRandi_2007.sph', 'JamesSurowiecki_2005.sph', 'JamesWatson_2005.sph', 'JamieHeywood_2009P.sph', 'JamieOliver_2010.sph', 'JamilAbuWardeh_2010G.sph', 'JanChipchase_2007.sph', 'JaneChen_2009I.sph', 'JaneGoodall_2002.sph', 'JaneGoodall_2007G.sph', 'JanePoynter_2009.sph', 'JanineBenyus_2005.sph', 'JanineBenyus_2009G.sph', 'JaredDiamond_2003.sph', 'JasonClay_2010G.sph', 'JasonFried_2010X.sph', 'JayWalker_2008.sph', 'JayWalker_2009.sph', 'JeffBezos_2003.sph', 'JeffHan_2006.sph', 'JeffHawkins_2003.sph', 'JeffreySkoll_2007.sph', 'JehaneNoujaim_2006.sph', 'Jennifer8Lee_2008P.sph', 'JenniferLin_2004.sph', 'JeremyJackson_2010Z.sph', 'JessaGamble_2010GU.sph', 'JessicaJackley_2010G.sph', 'JillBolteTaylor_2008.sph', 'JillSobuleandJuliaSweeneySHOW_2007.sph', 'JillSobuleMANHATTANINJANUARY_2006.sph', 'JillTarter_2009.sph', 'JimFallon_2009.sph', 'JimmyWales_2005G.sph', 'JimToomey_2010Z.sph', 'JJAbrams_2007.sph', 'JoachimdePosada_2009U.sph', 'JoAnnKucheraMorin_2009.sph', 'JodyWilliams_2010W.sph', 'JoeDeRisi_2006.sph', 'JoelLevine_2009X.sph', 'JohannaBlakley_2009X.sph', 'JohannaBlakley_2010W.sph', 'JohanRockstrom_2010G.sph', 'JohnDelaney_2010Z.sph', 'JohnDoerr_2007.sph', 'JohnFrancis_2008.sph', 'JohnGerzema_2009X.sph', 'JohnHardy_2010G.sph', 'JohnHodgman_2008.sph', 'JohnKasaona_2010.sph', 'JohnLaGrou_2009.sph', 'JohnLloyd_2009G.sph', 'JohnMaeda_2007.sph', 'JohnMaeda_2008P.sph', 'JohnnyLee_2008.sph', 'JohnUnderkoffler_2010.sph', 'JohnWalker_2007P.sph', 'JohnWooden_2001.sph', 'JonathanHaidt_2008.sph', 'JonathanHarris_2007.sph', 'JonathanHarris_2007P.sph', 'JonathanKlein_2010U.sph', 'JonathanZittrain_2009G.sph', 'JoseAntonioAbreu_2009.sph', 'JosephNye_2010G.sph', 'JosephPine_2004.sph', 'JoshSilver_2009G.sph', 'JoshuaKlein_2008.sph', 'JoshuaPrinceRamus_2006.sph', 'JoshuaPrinceRamus_2009X.sph', 'JuanEnriquez_2003.sph', 'JuanEnriquez_2007S.sph', 'JuanEnriquez_2009.sph', 'JulianaMachadoFerreira_2010U.sph', 'JulianAssange_2010G.sph', 'JulianTreasure_2009G.sph', 'JulianTreasure_2010GU.sph', 'JuliaSweeney_2006.sph', 'JuliaSweeney_2010.sph', 'KakiKing_2008.sph', 'KamalMeattle_2009U.sph', 'KarenArmstrong_2008.sph', 'KarenArmstrong_2009G.sph', 'KartickSatyanarayan_2009I.sph', 'KaryMullis_2002.sph', 'KaryMullis_2009.sph', 'KateOrff_2010W.sph', 'KatherineFulton_2007.sph', 'KeithBarry_2004.sph', 'KeithBellows_2002.sph', 'KeithSchachtandZachKaplan_2005.sph', 'KenKamler_2009P.sph', 'KevinBales_2010.sph', 'KevinKelly_2005.sph', 'KevinKelly_2007P.sph', 'KevinKelly_2009X.sph', 'KevinStone_2010U.sph', 'KevinSurace_2009.sph', 'KimGorgens_2010X.sph', 'KiranBedi_2010W.sph', 'KiranBirSethi_2009I.sph', 'KirkCitron_2010.sph', 'KRamdas_2009I.sph', 'KristenAshburn_2003.sph', 'KristinaGjerde_2010Z.sph', 'KwabenaBoahen_2007G.sph', 'LakshmiPratury_2007.sph', 'LaliteshKattragadda_2009I.sph', 'LarryBrilliant_2006.sph', 'LarryBrilliant_2007P.sph', 'LarryBurns_2005.sph', 'LarryLessig_2007.sph', 'LauraTrice_2008.sph', 'LaurieGarrett_2007U.sph', 'LaurieSantos_2010G.sph', 'LawrenceLessig_2010X.sph', 'LeeHotz_2010G.sph', 'LeeSmolin_2003.sph', 'LennartGreen_2005.sph', 'LesleyHazleton_2010X.sph', 'LewisPugh_2009G.sph', 'LewisPugh_2010G.sph', 'LisaMargonelli_2010X.sph', 'list.txt', 'LizaDonnelly_2010W.sph', 'LizColeman_2009.sph', 'LizDiller_2007P.sph', 'LorettaNapoleoni_2009G.sph', 'LouiseFresco_2009.sph', 'LouiseLeakey_2008.sph', 'LucaTurin_2005.sph', 'MaeJemison_2002.sph', 'MagnusLarsson_2009G.sph', 'MairaKalman_2007.sph', 'MajoraCarter_2006.sph', 'MajoraCarter_2010X.sph', 'MalcolmGladwell_2004.sph', 'MallikaSarabhai_2009I.sph', 'MarcelDicke_2010G.sph', 'MarcKoska_2009G.sph', 'MarcPachter_2008P.sph', 'MarcusduSautoy_2009G.sph', 'MargaretStewart_2010U.sph', 'MargaretWertheim_2009.sph', 'MarianBantjes_2010.sph', 'MarisaFickJordan_2007G2.sph', 'MarkBittman_2007P.sph', 'MarkRoth_2010.sph', 'MartinJacques_2010S.sph', 'MartinRees_2005G.sph', 'MarvinMinsky_2003.sph', 'MaryRoach_2009.sph', 'MathieuLehanneur_2009G.sph', 'MatthewChilds_2009U.sph', 'MatthieuRicard_2004.sph', 'MattRidley_2010G.sph', 'MazJobrani_2010G.sph', 'MechaiViravaidya_2010X.sph', 'MelindaGates_2010X.sph', 'MenaTrott_2006.sph', 'MichaelMerzenich_2004.sph', 'MichaelMilken_2001.sph', 'MichaelMoschen_2002.sph', 'MichaelPollan_2007.sph', 'MichaelPritchard_2009G.sph', 'MichaelSandel_2010.sph', 'MichaelShermer_2006.sph', 'MichaelShermer_2010.sph', 'MichelleObama_2009P.sph', 'MihalyCsikszentmihalyi_2004.sph', 'MikedeGruy_2010Z.sph', 'MikeRowe_2008P.sph', 'MiltonGlaser_1998.sph', 'MiruKim_2008P.sph', 'MishaGlenny_2009G.sph', 'MitchellJoachim_2010.sph', 'MosheSafdie_2002.sph', 'MurrayGellMann_2007.sph', 'MurrayGellMannLANGUAGE_2007.sph', 'NaifAlMutawa_2010G.sph', 'NaliniNadkarni_2009.sph', 'NaliniNadkarni_2010U.sph', 'name.bat', 'NancyEtcoff_2004.sph', 'NandanNilekani_2009.sph', 'NaomiKlein_2010W.sph', 'NatalieJeremijenko_2009P.sph', 'NatalieMerchant_2010.sph', 'NatashaTsakos_2009.sph', 'NateSilver_2009.sph', 'NathanielKahn_2002.sph', 'NathanMyhrvold_2007.sph', 'NathanMyhrvold_2010.sph', 'NathanWolfe_2009.sph', 'Naturally7FLYBABY_2009.sph', 'NeilGershenfeld_2006.sph', 'NeilPasricha_2010X.sph', 'NeilTurok_2008.sph', 'NellieMcKayCLONIE_2008.sph', 'NellieMcKayFEMINISTSIF_2008.sph', 'NellieMcKayTHEDOGSONG_2008.sph', 'NewtonAduaka_2007G.sph', 'NgoziOkonjoIweala_2007.sph', 'NgoziOkonjoIweala_2007G.sph', 'NicholasChristakis_2010.sph', 'NicholasChristakis_2010S.sph', 'NicholasNegroponte_1984.sph', 'NicholasNegroponte_2006.sph', 'NicholasNegroponte_2007P.sph', 'NicholasNegroponte_2008.sph', 'NickBostrom_2005G.sph', 'NickSears_2007.sph', 'NickVeasey_2009G.sph', 'NicMarks_2010G.sph', 'NielsDiffrient_2002a.sph', 'NinaJablonski_2009.sph', 'NoahFeldman_2003.sph', 'NoraYorkWHATIWANT_2006S.sph', 'NormanFoster_2007P.sph', 'NuclearDebate_2010.sph', 'OlafurEliasson_2009.sph', 'OliverSacks_2009.sph', 'OmarAhmad_2010U.sph', 'OryOkolloh_2007G.sph', 'PameliaKurstin_2002.sph', 'PaolaAntonelli_2007.sph', 'PaolaAntonelli_2007P.sph', 'ParagKhanna_2009G.sph', 'PatriciaBurchat_2008.sph', 'PatrickAwuah_2007G.sph', 'PatrickChappatte_2010G.sph', 'PattieMaes_2009.sph', 'PaulaScher_2008P.sph', 'PaulBennett_2005G.sph', 'PaulCollier_2008.sph', 'PaulCollier_2009S.sph', 'PaulDebevec_2009X.sph', 'PaulEwald_2007.sph', 'PaulMacCready_1998.sph', 'PaulMacCready_2003.sph', 'PaulMoller_2004.sph', 'PaulRomer_2009G.sph', 'PaulRothemund_2007.sph', 'PaulRothemund_2008.sph', 'PaulSereno_2005.sph', 'PaulStamets_2008.sph', 'PawanSinha_2009I.sph', 'PenelopeBoston_2006.sph', 'PeterDiamandis_2005G.sph', 'PeterDiamandis_2008.sph', 'PeterDonnelly_2005G.sph', 'PeterEigen_2009X.sph', 'PeterGabriel_2006.sph', 'PeterHaas_2010G.sph', 'PeterHirshberg_2007P.sph', 'PeterMolyneux_2010G.sph', 'PeterReinhart_2008P.sph', 'PeterTyack_2010Z.sph', 'PeterWard_2008.sph', 'PhilBorges_2006.sph', 'PhilipHoward_2010.sph', 'PhilippeStarck_2007.sph', 'PhilipRosedale_2008P.sph', 'PhilZimbardo_2008.sph', 'PhilZimbardo_2009U.sph', 'PranavMistry_2009I.sph', 'PWSinger_2009.sph', 'RachelArmstrong_2009G.sph', 'RachelBotsman_2010X.sph', 'RachelPike_2009G.sph', 'RachelSussman_2010G.sph', 'RaghavaKK_2010.sph', 'RAMashelkar_2009I.sph', 'RaulMidonANSWERS_2007.sph', 'RaulMidonEVERYBODY_2007.sph', 'RavinAgrawal_2009I.sph', 'RayAnderson_2009.sph', 'RayKurzweil_2005.sph', 'RayKurzweil_2009U.sph', 'RayZahab_2009.sph', 'RebeccaSaxe_2009G.sph', 'ReedKroloff_2003.sph', 'RennyGleeson_2009.sph', 'RichardBaraniuk_2006.sph', 'RichardBranson_2007.sph', 'RichardDawkins_2002.sph', 'RichardDawkins_2005G.sph', 'RichardPreston_2008.sph', 'RichardPyle_2004.sph', 'RichardSears_2010U.sph', 'RichardSt.John_2005.sph', 'RichardStJohn_2009U.sph', 'RickSmolan_2007P.sph', 'RickWarren_2006.sph', 'Rives4AM_2007.sph', 'RivesINTERNET_2006S.sph', 'RivesMOCKINGBIRD_2006.sph', 'RivesTTYL_2008.sph', 'RobDunbar_2010Z.sph', 'RobertBallard_2008.sph', 'RobertFischell_2005.sph', 'RobertFull_2002.sph', 'RobertFull_2005.sph', 'RobertFull_2009.sph', 'RobertLang_2008.sph', 'RobertNeuwirth_2005.sph', 'RobertThurman_2009P.sph', 'RobertWright_2006.sph', 'RobertWright_2009P.sph', 'RobForbes_2006.sph', 'RobHopkins_2009G.sph', 'RobinChase_2007.sph', 'RodneyBrooks_2003.sph', 'RomulusWhitaker_2009I.sph', 'RonEglash_2007G2.sph', 'RoryBremner_2009G.sph', 'RorySutherland_2009G.sph', 'RorySutherland_2010S.sph', 'RossLovegrove_2005.sph', 'RoyGould_2008.sph', 'RozSavage_2010Z.sph', 'RufusGriscomandAlisaVolkman_2010W.sph', 'RyanLobo_2009I.sph', 'SamanthaPower_2008.sph', 'SamHarris_2010.sph', 'SamMartin_2009G.sph', 'SarahJones_2009.sph', 'Saraswati_2009P.sph', 'SasaVucinic_2005G.sph', 'SaulGriffith_2009.sph', 'ScottKim_2008P.sph', 'ScottMcCloud_2005.sph', 'SeanGourley_2009U.sph', 'SebastianSeung_2010G.sph', 'SebastianWernicke_2010A.sph', 'SendhilMullainathan_2009I.sph', 'SergeyBrin_2004.sph', 'SethBerkley_2010.sph', 'SethGodin_2003.sph', 'SethGodin_2009.sph', 'SethPriebatsch_2010X.sph', 'SeyiOyesola_2007G.sph', 'ShaffiMather_2009I.sph', 'ShaiAgassi_2009.sph', 'SharmeenObaidChinoy_2010U.sph', 'ShashiTharoor_2009I.sph', 'SheenaIyengar_2010G.sph', 'SheilaPatek_2004.sph', 'ShekharKapur_2009I.sph', 'ShereenElFeki_2009G.sph', 'SherwinNuland_2001.sph', 'SherwinNuland_2003.sph', 'SherylSandberg_2010W.sph', 'SherylWuDunn_2010G.sph', 'ShimonSchocken_2010X.sph', 'ShimonSteinberg_2010X.sph', 'ShuklaBose_2009I.sph', 'SiegfriedWoldhek_2008.sph', 'SimonSinek_2009X.sph', 'SirenaHuang_2006.sph', 'SirKenRobinson_2006.sph', 'SirKenRobinson_2010.sph', 'SophalEar_2009U.sph', 'SpencerWells_2007G.sph', 'StaceyKramer_2010.sph', 'StefanaBroadbent_2009G.sph', 'StefanoMancuso_2010G.sph', 'StefanSagmeister_2004.sph', 'StefanSagmeister_2008.sph', 'StefanSagmeister_2009G.sph', 'StefanWolff_2010G.sph', 'StephenHawking_2008.sph', 'StephenLawler_2007.sph', 'StephenPalumbi_2010Z.sph', 'StephenPetranek_2002.sph', 'StephenWolfram_2010.sph', 'SteveJurvetson_2007.sph', 'StevenCowley_2009G.sph', 'StevenJohnson_2003.sph', 'StevenJohnson_2006S.sph', 'StevenJohnson_2010G.sph', 'StevenLevitt_2004.sph', 'StevenLevitt_2005G.sph', 'StevenPinker_2003.sph', 'StevenPinker_2005G.sph', 'StevenPinker_2007.sph', 'StevenStrogatz_2004R.sph', 'SteveTruglia_2009G.sph', 'StewartBrand_2004.sph', 'StewartBrand_2006.sph', 'StewartBrand_2009S.sph', 'StewBLACKMENSKI_2006.sph', 'StuartBrown_2008P.sph', 'SugataMitra_2007P.sph', 'SugataMitra_2010G.sph', 'SuheirHammad_2010W.sph', 'SunithaKrishnan_2009I.sph', 'SusanBlackmore_2008.sph', 'SusanSavageRumbaugh_2004.sph', 'SusanShaw_2010X.sph', 'SylviaEarle_2009.sph', 'TanLe_2010G.sph', 'TarynSimon_2009G.sph', 'TempleGrandin_2010.sph', 'TeresaCarrenoOrchestra_2009.sph', 'ThelmaGolden_2009.sph', 'TheLXD_2010.sph', 'TheoJansen_2007.sph', 'TheRaspyniBrothers_2002.sph', 'TheyMightBeGiants_2007.sph', 'ThomasBarnett_2005.sph', 'ThomasDolby_2010.sph', 'ThomasDolbyandRachelleGarniezLAVIEENROSE_2004.sph', 'ThomasGoetz_2010P.sph', 'ThomasThwaites_2010S.sph', 'ThomMayne_2005.sph', 'ThulasirajRavilla_2009I.sph', 'TierneyThys_2003.sph', 'TimBernersLee_2009.sph', 'TimBernersLee_2010U.sph', 'TimBrown_2008P.sph', 'TimBrown_2009G.sph', 'TimFerriss_2008P.sph', 'TimJackson_2010G.sph', 'TodMachover_2008.sph', 'TomChatfield_2010G.sph', 'TomHoney_2005.sph', 'TomRielly_2006.sph', 'TomShannon_2003.sph', 'TomShannon_2009S.sph', 'TomWujec_2009GU.sph', 'TomWujec_2009U.sph', 'TonyPorter_2010W.sph', 'TonyRobbins_2006.sph', 'TorstenReil_2003.sph', 'UeliGegenschatz_2009.sph', 'UrsusWehrli_2006.sph', 'VanJones_2010X.sph', 'VikMuniz_2003.sph', 'VilayanurRamachandran_2007.sph', 'VilayanurRamachandran_2009I.sph', 'VirginiaPostrel_2004.sph', 'VusiMahlaselaSONGOFMAMA_2007G.sph', 'WadeDavis_2008.sph', 'WillardWigan_2009G.sph', 'WilliamKamkwamba_2007G.sph', 'WilliamKamkwamba_2009G.sph', 'WilliamLi_2010.sph', 'WilliamMcDonough_2005.sph', 'WilliamUry_2010X.sph', 'WillieSmits_2009.sph', 'WillWright_2007.sph', 'WoodyNorris_2004.sph', 'XDRTB_2008.sph', 'YannArthusBertrand_2009.sph', 'YochaiBenkler_2005G.sph', 'YossiVardi_2007.sph', 'YvesBehar_2008.sph', 'YvesBehar_2009.sph', 'ZainabSalbi_2010G.sph', 'ZeFrank_2004.sph', 'ZeFrank_2010G.sph', 'ZeresenayAlemseged_2007G.sph']\n"
          ]
        }
      ],
      "source": [
        "filenames = []\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/term project/ted_info.txt')\n",
        "for line in f.readlines():\n",
        "    filenames.append(line[0:len(line)-1])\n",
        "f.close\n",
        "print(filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTC8I2rVzJSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a8db21-4087-4f70-8ccf-a26867d9599f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['name', 'words_number', 'SPACE', 'ADV', 'VERB', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'INTJ', 'NUM', 'PRON', 'AUX', 'CCONJ', 'PART', 'PROPN', 'SCONJ', 'CONJ', 'Punctuation', 'hestitation_word', 'lemma_number', 'most_frequent', 'noun_chunk', 'person_singular_verbs', 'misspell', 'time_spec', 'spec', 'sentence', 'neg_word', 'content', 'function', 'SPACE_R', 'ADV_R', 'VERB_R', 'ADP_R', 'DET_R', 'NOUN_R', 'ADJ_R', 'PUNCT_R', 'INTJ_R', 'NUM_R', 'PRON_R', 'AUX_R', 'CCONJ_R', 'PART_R', 'PROPN_R', 'SCONJ_R', 'CONJ_R', 'Punctuation_R', 'hestitation_word_R', 'lemma_number_R', 'person_singular_verbs_R', 'misspell_R', 'time_spec_R', 'spec_R', 'neg_word_R', 'content_R', 'function_R', 'time_split', 'wordnum_t', 'SPACE_t', 'ADV_t', 'VERB_t', 'ADP_t', 'DET_t', 'NOUN_t', 'ADJ_t', 'PUNCT_t', 'INTJ_t', 'NUM_t', 'PRON_t', 'AUX_t', 'CCONJ_t', 'PART_t', 'PROPN_t', 'SCONJ_t', 'CONJ_t', 'Punctuation_t', 'hestitation_word_t', 'lemma_number_t', 'most_frequent_t', 'noun_chunk_t', 'person_singular_verbs_t', 'misspell_t', 'time_spec_t', 'spec_t', 'sentence_t', 'neg_word_t', 'content_t', 'function_t', 'mean_ttr', 'total_ttr', 'max_ttr', 'mean_mattr', 'total_mattr', 'max_mattr', 'mean_brunet_index', 'total_brunet_index', 'max_brunet_index', 'mean_honore_statistic', 'total_honore_statistic', 'max_honore_statistic', 'good_emoji', 'no_emoji', 'bad_emoji', 'mean_sdl', 'total_sdl', 'max_sdl', 'mean_Yngve_depth', 'total_Yngve_depth', 'max_Yngve_depth', 'mean_left_branching', 'total_left_branching', 'max_left_branching', 'frazer_chunk', 'max_frazer_depth', 'mean_frazer_depth']\n"
          ]
        }
      ],
      "source": [
        "old_data=[]\n",
        "feature_list=[]\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/term project/after_syanalysis.csv', 'r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    feature_list=next(csv_reader)\n",
        "    for row in csv_reader:\n",
        "        old_data.append(row)\n",
        "#add_feature=['mean_Yngve_depth','total_Yngve_depth','max_Yngve_depth','mean_left_branching','total_left_branching','max_left_branching']\n",
        "add_feature=['mean_frazer_depth']\n",
        "for i in range(0,len(add_feature)):\n",
        "  feature_list.append(add_feature[i])\n",
        "print(feature_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5d69FDP_Snc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754ad53b-1647-4b62-9f0b-d596cce60f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fail on sentence!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tree import Tree\n",
        "def syntactic_analysis(text):\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  max_frazer_depth=-1\n",
        "  frazer_chunk=0\n",
        "  frazer_depth=[]\n",
        "  for sentence in sentences:\n",
        "    if(len(sentence)>200):\n",
        "      continue\n",
        "    try:\n",
        "      result = list(parser.parse(sentence.split()))\n",
        "      tree = result[0]\n",
        "      def calculate_frazer_depth_for_sentence(tree):\n",
        "          frazer_depths = {}\n",
        "          def calculate_frazer_depth_for_word(node, word, depth=0):\n",
        "            total_younger_sisters = 0\n",
        "            def count_younger_sisters(node):\n",
        "                nonlocal total_younger_sisters\n",
        "                for i, child in enumerate(node):\n",
        "                    if isinstance(child, Tree):\n",
        "                        total_younger_sisters += len(node) - 1 - i\n",
        "                        count_younger_sisters(child)\n",
        "            count_younger_sisters(node)\n",
        "            return total_younger_sisters\n",
        "          for subtree in tree.subtrees():\n",
        "            if isinstance(subtree, Tree):\n",
        "              word = \" \".join(subtree.leaves())\n",
        "              frazer_depth = calculate_frazer_depth_for_word(subtree, word)\n",
        "              frazer_depths[word] = frazer_depth\n",
        "          return frazer_depths\n",
        "      frazer_depths = calculate_frazer_depth_for_sentence(tree)\n",
        "      all_depth=0\n",
        "      temp_chunk=0\n",
        "      for word, depth in frazer_depths.items():\n",
        "        frazer_chunk+=1\n",
        "        temp_chunk+=1\n",
        "        all_depth+=depth\n",
        "        if(depth > max_frazer_depth):\n",
        "          max_frazer_depth=depth\n",
        "      frazer_depth.append(all_depth/temp_chunk)\n",
        "    except:\n",
        "      print(\"fail on sentence!\")\n",
        "      continue\n",
        "  return max_frazer_depth,frazer_chunk,frazer_depth\n",
        "max_frazer_depth,frazer_chunk,frazer_depth=syntactic_analysis(\"I like to eat fish, and I also enjoy swimming.I like you as well.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tree import Tree\n",
        "from nltk.parse.corenlp import CoreNLPParser\n",
        "\n",
        "def syntactic_analysis(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    yngve_depth = []\n",
        "    left_branching = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "      if(len(sentence)>180):\n",
        "        continue\n",
        "      try:\n",
        "        result = list(parser.parse(sentence.split()))\n",
        "        tree = result[0]\n",
        "\n",
        "        def calculate_depth(tree, measure='yngve'):\n",
        "            if measure == 'yngve':\n",
        "                return calculate_yngve_depth(tree)\n",
        "            elif measure == 'left_branching':\n",
        "                return calculate_left_branching(tree)\n",
        "\n",
        "        def calculate_yngve_depth(tree, depth=0):\n",
        "            max_depth = depth\n",
        "            for child in tree:\n",
        "                if isinstance(child, Tree):\n",
        "                    child_depth = calculate_yngve_depth(child, depth + 1)\n",
        "                    max_depth = max(max_depth, child_depth)\n",
        "            return max_depth\n",
        "\n",
        "        def calculate_left_branching(tree, count=0):\n",
        "            for i, child in enumerate(tree):\n",
        "                if isinstance(child, Tree):\n",
        "                    if i < len(tree) - 1:\n",
        "                        count += 1\n",
        "                    count = calculate_left_branching(child, count)\n",
        "            return count\n",
        "\n",
        "        yngve_depth.append(calculate_depth(tree, measure='yngve'))\n",
        "        left_branching.append(calculate_depth(tree, measure='left_branching'))\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        continue\n",
        "    return yngve_depth, left_branching\n"
      ],
      "metadata": {
        "id": "46e-cxkGDzSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6Y21PRpx64N"
      },
      "outputs": [],
      "source": [
        "from nltk.tree import Tree\n",
        "from nltk.parse.corenlp import CoreNLPParser\n",
        "\n",
        "def calculate_t_unit_lengths(tree):\n",
        "    t_unit_lengths = []\n",
        "\n",
        "    def traverse_tree(subtree):\n",
        "        nonlocal t_unit_lengths\n",
        "\n",
        "        if isinstance(subtree, Tree):\n",
        "            if subtree.label() in ('S', 'SINV', 'SQ', 'SBAR'):\n",
        "                t_unit = subtree.leaves()\n",
        "                t_unit_length = len(t_unit)\n",
        "                t_unit_lengths.append(t_unit_length)\n",
        "            else:\n",
        "                for child in subtree:\n",
        "                    traverse_tree(child)\n",
        "    traverse_tree(tree)\n",
        "    return t_unit_lengths\n",
        "\n",
        "def cal_tunit(line1):\n",
        "    line = line1.split('.')\n",
        "    mean_t_unit = []\n",
        "\n",
        "    for i in range(0, len(line)-1):\n",
        "        print(line[i])\n",
        "        parser = CoreNLPParser(url='http://localhost:9001')\n",
        "        sentence = line[i]\n",
        "        result = list(parser.raw_parse(sentence))\n",
        "        tree = result[0]\n",
        "\n",
        "        t_unit_lengths = calculate_t_unit_lengths(tree)\n",
        "        mean_t_unit_length = sum(t_unit_lengths) / len(t_unit_lengths) if t_unit_lengths else 0\n",
        "        mean_t_unit.append(mean_t_unit_length)\n",
        "        print(\"complete\")\n",
        "    return mean_t_unit\n",
        "print(cal_tunit(\"I like to eat fish, and I also enjoy swimming.\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tree import Tree\n",
        "from nltk.parse.corenlp import CoreNLPParser\n",
        "fail_list=[]\n",
        "nltk.download('punkt')\n",
        "# Start the Stanford CoreNLP server first before running this script\n",
        "parser = CoreNLPParser(url='http://localhost:4015')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ7T1qJ6Q-Hl",
        "outputId": "ab086c40-bada-4bae-a9b6-8539cd2584d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD7VH0b40pxD"
      },
      "outputs": [],
      "source": [
        "for i in range(0,len(filenames)):\n",
        "  try:\n",
        "    print(filenames[i])\n",
        "    source_file_path='/content/drive/MyDrive/Colab Notebooks/term project/TED text/'+filenames[i][0:len(filenames[i])-4]+'.txt'\n",
        "    f1 = open(source_file_path, \"r\")\n",
        "    line1 = f1.readline()\n",
        "    f1.close()\n",
        "    frazer_chunk,max_frazer_depth,frazer_depth=syntactic_analysis(line1)\n",
        "    #mean_Yngve_depth','total_Yngve_depth','max_Yngve_depth','mean_left_branching','total_left_branching','max_left_branching','frazer_chunk','max_frazer_depth','mean_frazer_depth']\n",
        "    for j in range(0,len(old_data)):\n",
        "      if(old_data[j][0]==filenames[i]):\n",
        "        old_data[j].append(frazer_chunk)\n",
        "        old_data[j].append(max_frazer_depth)\n",
        "        old_data[j].append(np.mean(frazer_depth))\n",
        "        #print(\"complete\",filenames[i])\n",
        "        print(\"complete!!!!!\")\n",
        "        break\n",
        "  except:\n",
        "    fail_list.append(filenames[i])\n",
        "    print(\"fail in\",filenames[i])\n",
        "    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI2pcv1Ye3N-"
      },
      "outputs": [],
      "source": [
        "filename='AdamSavage_2008P.sph'\n",
        "source_file_path='/content/drive/MyDrive/Colab Notebooks/term project/TED text/AdamSavage_2008P.txt'\n",
        "f1 = open(source_file_path, \"r\")\n",
        "line1 = f1.readline()\n",
        "f1.close()\n",
        "line1=line1.split('.')\n",
        "for i in range(0,len(line1)):\n",
        "  print(len(line1[i].split(' ')))\n",
        "print(line1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z5LXmBR_1c0"
      },
      "outputs": [],
      "source": [
        "client.stop()\n",
        "\n",
        "time.sleep(10)\n",
        "!ps -o pid,cmd | grep java"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}