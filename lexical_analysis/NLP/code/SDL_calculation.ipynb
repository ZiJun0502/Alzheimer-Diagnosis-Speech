{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf3SQNDTaspG"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!pip install nltk\n",
        "!pip install stanza\n",
        "!pip install scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from google.colab import drive\n",
        "import csv\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "nltk.download('stopwords')\n",
        "import spacy\n",
        "import stanza\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nltk.download('punkt')\n",
        "stanza.download('en')"
      ],
      "metadata": {
        "id": "oMkspuQxcm1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import statistics"
      ],
      "metadata": {
        "id": "JClDC4U9YEDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = []\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/term project/ted_info.txt')\n",
        "for line in f.readlines():\n",
        "    filenames.append(line[0:len(line)-1])\n",
        "f.close\n",
        "print(filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JtrprsZlwfi",
        "outputId": "ba86df41-16c6-4000-99ef-605ff4b5e38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AaronHuey_2010X.sph', 'AdamGrosser_2007.sph', 'AdamSadowsky_2010X.sph', 'AdamSavage_2008P.sph', 'AditiShankardass_2009I.sph', 'AdoraSvitak_2010.sph', 'AimeeMullins_1998.sph', 'AimeeMullins_2009U.sph', 'AJJacobs_2007P.sph', 'AlaindeBotton_2009G.sph', 'AlanKay_2007.sph', 'AlanRussell_2006.sph', 'AlanSiegel_2010.sph', 'AlexisOhanian_2009I.sph', 'AlexTabarrok_2009.sph', 'AlGore_2006.sph', 'AlGore_2008.sph', 'AliCarrChellman_2010X.sph', 'AlisonJackson_2005G.sph', 'AllisonHunt_2007.sph', 'AlSeckel_2004.sph', 'AndersYnnerman_2010X.sph', 'AndrewMwenda_2007G.sph', 'AnilGupta_2009I.sph', 'AnnaDeavereSmith_2005.sph', 'AnthonyAtala_2009P.sph', 'AnupamMishra_2009I.sph', 'AriannaHuffington_2010W.sph', 'ArthurBenjamin_2005.sph', 'ArthurBenjamin_2009.sph', 'ArthurGanson_2004.sph', 'ArthurPottsDawson_2010G.sph', 'AsherHasan_2009I.sph', 'AshrafGhani_2005G.sph', 'AubreydeGrey_2005G.sph', 'AuretvanHeerden_2010G.sph', 'BarbaraBlock_2010Z.sph', 'BarrySchuler_2008P.sph', 'BarrySchwartz_2009.sph', 'BarrySchwartz_2010S.sph', 'BartonSeaver_2010Z.sph', 'BartWeetjens_2010X.sph', 'BeauLotto_2009G.sph', 'BeckyBlanton_2009G.sph', 'BenCameron_2010X.sph', 'BenDunlap_2007.sph', 'BenjaminWallace_2008P.sph', 'BenjaminZander_2008.sph', 'BenKatchor_2002.sph', 'BenoitMandelbrot_2010.sph', 'BenSaunders_2005.sph', 'BertrandPiccard_2009G.sph', 'BeverlyJoubertandDereckJoubert_2010W.sph', 'BillClinton_2007.sph', 'BillDavenhall_2009P.sph', 'BillGates_2009.sph', 'BillGross_2003.sph', 'BillJoy_2006.sph', 'BillStone_2007.sph', 'BillStrickland_2002.sph', 'BillyGraham_1998.sph', 'BirkeBaehr_2010X.sph', 'BjarkeIngels_2009G.sph', 'BjornLomborg_2005.sph', 'BlaiseAguerayArcas_2010.sph', 'BobThurman_2006S.sph', 'BonnieBassler_2009.sph', 'Bono_2005.sph', 'BrendaLaurel_1998.sph', 'BreneBrown_2010X.sph', 'BrewsterKahle_2007P.sph', 'BrianCox_2008.sph', 'BrianCox_2010S.sph', 'BrianGreene_2005.sph', 'BrianSkerry_2010Z.sph', 'BruceBuenodeMesquita_2009.sph', 'BruceFeiler_2010P.sph', 'BruceMcCall_2008P.sph', 'BrunoBowden_2008.sph', 'BurtRutan_2006.sph', 'CalebChung_2007P.sph', 'CameronHerold_2009X.sph', 'CameronSinclair_2006.sph', 'CameronSinclair_2009G.sph', 'CarlHonore_2005G.sph', 'CarlSafina_2010X.sph', 'CarmenAgraDeedy_2005.sph', 'CarneRoss_2009P.sph', 'CarolineLavelleFARTHERTHANTHESUN_2005.sph', 'CarolinePhillips_2010G.sph', 'CarolynPorco_2007.sph', 'CarolynPorco_2009U.sph', 'CarolynSteel_2009G.sph', 'CarterEmmart_2010.sph', 'CaryFowler_2009G.sph', 'CatherineMohr_2009.sph', 'CatherineMohr_2010U.sph', 'CharityTillemannDick_2010P.sph', 'CharlesAnderson_2009I.sph', 'CharlesElachi_2008P.sph', 'CharlesFleischer_2005.sph', 'CharlesLeadbeater_2005G.sph', 'CharlesLeadbeater_2010S.sph', 'CharlesLimb_2010X.sph', 'CharlesMoore_2009U.sph', 'ChimamandaAdichie_2009G.sph', 'ChipConley_2010.sph', 'ChrisAbani_2007G.sph', 'ChrisAbani_2008.sph', 'ChrisAnderson_2002.sph', 'ChrisAnderson_2004.sph', 'ChrisAnderson_2010G.sph', 'ChrisBangle_2002.sph', 'ChrisJordan_2008.sph', 'ChristienMeindertsma_2010G.sph', 'ChristopherDeam_2002.sph', 'ChristopherdeCharms_2008.sph', 'ChristopherMcDougall_2010X.sph', 'ChristopherPoole_2010.sph', 'CKWilliams_2001.sph', 'ClayShirky_2005G.sph', 'ClayShirky_2009S.sph', 'ClayShirky_2010S.sph', 'CliffordStoll_2006.sph', 'ConradWolfram_2010G.sph', 'CorneilleEwango_2007G.sph', 'CraigVenter_2005G.sph', 'CraigVenter_2010P.sph', 'CynthiaSchneider_2009G.sph', 'DanAriely_2008P.sph', 'DanAriely_2009.sph', 'DanBarber_2008P.sph', 'DanBuettner_2009X.sph', 'DanCobley_2010G.sph', 'DanDennett_2002.sph', 'DanDennett_2003.sph', 'DanDennett_2006.sph', 'DanDennett_2009U.sph', 'DanGilbert_2004.sph', 'DanGilbert_2005G.sph', 'DanielGoleman_2007.sph', 'DanielKraft_2009.sph', 'DanielLibeskind_2009.sph', 'DanielPink_2009G.sph', 'DanMeyer_2010X.sph', 'DanPhillips_2010X.sph', 'DaveEggers_2008.sph', 'DavidAgus_2009P.sph', 'DavidBismark_2010G.sph', 'DavidBlaine_2009P.sph', 'DavidBolinsky_2007.sph', 'DavidByrne_2010.sph', 'DavidCameron_2010.sph', 'DavidCarson_2003.sph', 'DavidDeutsch_2005G.sph', 'DavidDeutsch_2009G.sph', 'DavidGallo_1998.sph', 'DavidGallo_2007.sph', 'DavidGriffin_2008.sph', 'DavidHanson_2009.sph', 'DavidHoffman_2007.sph', 'DavidHoffman_2008.sph', 'DavidHolt_2004.sph', 'DavidKeith_2007S.sph', 'DavidKelley_2002.sph', 'DavidLogan_2009.sph', 'DavidMacaulay_2002.sph', 'DavidMcCandless_2010G.sph', 'DavidPerry_2006.sph', 'DavidPogue_2006.sph', 'DavidPogue_2007.sph', 'DavidPogue_2008P.sph', 'DavidRockwell_2002.sph', 'DavidSRose_2007U.sph', 'DeanKamen_2002.sph', 'DeanKamen_2007.sph', 'DeanKamen_2009P.sph', 'DeanOrnish_2004.sph', 'DeanOrnish_2006.sph', 'DeanOrnish_2008.sph', 'DeborahGordon_2003.sph', 'DeborahRhodes_2010W.sph', 'DeborahScranton_2007.sph', 'DeeBoersma_2010Z.sph', 'DenisDutton_2010.sph', 'DennisHong_2009X.sph', 'DennisvanEngelsdorp_2008P.sph', 'DerekSivers_2009I.sph', 'DerekSivers_2010G.sph', 'DerekSivers_2010U.sph', 'DevduttPattanaik_2009I.sph', 'DianaLaufenberg_2010X.sph', 'DianeBenscoter_2009U.sph', 'DiannaCohen_2010Z.sph', 'DimitarSasselov_2010G.sph', 'DonNorman_2003.sph', 'DorisKearnsGoodwin_2008.sph', 'EamesDemetrios_2007.sph', 'EbenBayer_2010G.sph', 'EddiReaderWHATYOUDO_2004.sph', 'EdUlbrich_2009.sph', 'EdwardBurtynsky_2005.sph', 'EdwardBurtynsky_2009G.sph', 'EinsteinTheParrot_2006.sph', 'ElaineMorgan_2009G.sph', 'EleniGabreMadhin_2007G.sph', 'ElifShafak_2010G.sph', 'ElizabethLesser_2010W.sph', 'ElizabethPisani_2010.sph', 'EllenDunhamJones_2010X.sph', 'EllenGustafson_2010X.sph', 'EmilyLevine_2002.sph', 'EmilyOster_2007.sph', 'EmilyPilloton_2010G.sph', 'EmmanuelJal_2009G.sph', 'EnricSala_2010Z.sph', 'EOWilson_2007.sph', 'EricBerlow_2010G.sph', 'EricDishman_2009P.sph', 'EricGiler_2009G.sph', 'EricSanderson_2009G.sph', 'EricTopol_2009P.sph', 'ErikHersman_2009U.sph', 'ErinMcKean_2007.sph', 'ErnestMadu_2007G.sph', 'EstherDuflo_2010.sph', 'EthanZuckerman_2010G.sph', 'EuvinNaidoo_2007G.sph', 'EvanGrant_2009G.sph', 'EvanWilliams_2009.sph', 'EvaVertes_2005.sph', 'EvaZeisel_2001.sph', 'EveEnsler_2004.sph', 'EveEnsler_2005G.sph', 'EveEnsler_2009I.sph', 'EvelynGlennie_2003.sph', 'EvgenyMorozov_2009G.sph', 'EWidder_2010Z.sph', 'FabianHemmert_2009X.sph', 'FeisalAbdulRauf_2009P.sph', 'FelixDennis_2004.sph', 'FieldsWickerMiurin_2009S.sph', 'FrancoSacchi_2007G.sph', 'FrankGehry_1990.sph', 'FrankGehry_2002.sph', 'FransLanting_2005.sph', 'FrederickBalagadde_2010U.sph', 'FreemanDyson_2003.sph', 'GarikIsraelian_2009G.sph', 'GarrettLisi_2008.sph', 'GaryLauder_2010.sph', 'GaryWolf_2010S.sph', 'GeoffMulgan_2009G.sph', 'GeorgeAyittey_2007G.sph', 'GeorgeDyson_2002.sph', 'GeorgeDyson_2003.sph', 'GeorgeSmoot_2008P.sph', 'GeorgeWhitesides_2009X.sph', 'GeorgeWhitesides_2010.sph', 'GeroMiesenboeck_2010G.sph', 'GeverTulley_2007U.sph', 'GeverTulley_2009.sph', 'GolanLevin_2004.sph', 'GolanLevin_2009.sph', 'GordonBrown_2009G.sph', 'GrahamHawkes_2005.sph', 'GrahamHill_2010.sph', 'GregLynn_2005.sph', 'GregoryPetsko_2008.sph', 'GregoryStock_2003.sph', 'GregStone_2010Z.sph', 'Halla_Tomasdottir_2010W.sph', 'HannaRosin_2010W.sph', 'HansRosling_2006.sph', 'HansRosling_2007.sph', 'HansRosling_2009.sph', 'HansRosling_2009I.sph', 'HansRosling_2009S.sph', 'HansRosling_2010S.sph', 'HansRosling_2010X.sph', 'HarshaBhogle_2009I.sph', 'HeatherKnight_2010W.sph', 'HectorRuiz_2007G.sph', 'HelenFisher_2006.sph', 'HelenFisher_2008.sph', 'HeribertWatzke_2010G.sph', 'HillelCooperman_2010U.sph', 'HisHolinessTheKarmapa_2009I.sph', 'HodLipson_2007.sph', 'HowardRheingold_2005.sph', 'IanDunbar_2007P.sph', 'IanGoldin_2009G.sph', 'IngeMissmahl_2010G.sph', 'IqbalQuadir_2005G.sph', 'IrwinRedlener_2008.sph', 'IsaacMizrahi_2008.sph', 'IsabelAllende_2007.sph', 'ItayTalgam_2009G.sph', 'JacekUtko_2009.sph', 'JackieTabick_2009P.sph', 'JacquelineNovogratz_2005G.sph', 'JacquelineNovogratz_2007G.sph', 'JacquelineNovogratz_2009S.sph', 'JacquelineNovogratz_2009U.sph', 'JaimeLerner_2007.sph', 'JakeShimabukuro_2010.sph', 'JakobTrollback_2007.sph', 'JamaisCascio_2006.sph', 'JamesBalog_2009G.sph', 'JamesForbes_2009P.sph', 'JamesGeary_2009G.sph', 'JamesHowardKunstler_2004.sph', 'JamesRandi_2007.sph', 'JamesSurowiecki_2005.sph', 'JamesWatson_2005.sph', 'JamieHeywood_2009P.sph', 'JamieOliver_2010.sph', 'JamilAbuWardeh_2010G.sph', 'JanChipchase_2007.sph', 'JaneChen_2009I.sph', 'JaneGoodall_2002.sph', 'JaneGoodall_2007G.sph', 'JanePoynter_2009.sph', 'JanineBenyus_2005.sph', 'JanineBenyus_2009G.sph', 'JaredDiamond_2003.sph', 'JasonClay_2010G.sph', 'JasonFried_2010X.sph', 'JayWalker_2008.sph', 'JayWalker_2009.sph', 'JeffBezos_2003.sph', 'JeffHan_2006.sph', 'JeffHawkins_2003.sph', 'JeffreySkoll_2007.sph', 'JehaneNoujaim_2006.sph', 'Jennifer8Lee_2008P.sph', 'JenniferLin_2004.sph', 'JeremyJackson_2010Z.sph', 'JessaGamble_2010GU.sph', 'JessicaJackley_2010G.sph', 'JillBolteTaylor_2008.sph', 'JillSobuleandJuliaSweeneySHOW_2007.sph', 'JillSobuleMANHATTANINJANUARY_2006.sph', 'JillTarter_2009.sph', 'JimFallon_2009.sph', 'JimmyWales_2005G.sph', 'JimToomey_2010Z.sph', 'JJAbrams_2007.sph', 'JoachimdePosada_2009U.sph', 'JoAnnKucheraMorin_2009.sph', 'JodyWilliams_2010W.sph', 'JoeDeRisi_2006.sph', 'JoelLevine_2009X.sph', 'JohannaBlakley_2009X.sph', 'JohannaBlakley_2010W.sph', 'JohanRockstrom_2010G.sph', 'JohnDelaney_2010Z.sph', 'JohnDoerr_2007.sph', 'JohnFrancis_2008.sph', 'JohnGerzema_2009X.sph', 'JohnHardy_2010G.sph', 'JohnHodgman_2008.sph', 'JohnKasaona_2010.sph', 'JohnLaGrou_2009.sph', 'JohnLloyd_2009G.sph', 'JohnMaeda_2007.sph', 'JohnMaeda_2008P.sph', 'JohnnyLee_2008.sph', 'JohnUnderkoffler_2010.sph', 'JohnWalker_2007P.sph', 'JohnWooden_2001.sph', 'JonathanHaidt_2008.sph', 'JonathanHarris_2007.sph', 'JonathanHarris_2007P.sph', 'JonathanKlein_2010U.sph', 'JonathanZittrain_2009G.sph', 'JoseAntonioAbreu_2009.sph', 'JosephNye_2010G.sph', 'JosephPine_2004.sph', 'JoshSilver_2009G.sph', 'JoshuaKlein_2008.sph', 'JoshuaPrinceRamus_2006.sph', 'JoshuaPrinceRamus_2009X.sph', 'JuanEnriquez_2003.sph', 'JuanEnriquez_2007S.sph', 'JuanEnriquez_2009.sph', 'JulianaMachadoFerreira_2010U.sph', 'JulianAssange_2010G.sph', 'JulianTreasure_2009G.sph', 'JulianTreasure_2010GU.sph', 'JuliaSweeney_2006.sph', 'JuliaSweeney_2010.sph', 'KakiKing_2008.sph', 'KamalMeattle_2009U.sph', 'KarenArmstrong_2008.sph', 'KarenArmstrong_2009G.sph', 'KartickSatyanarayan_2009I.sph', 'KaryMullis_2002.sph', 'KaryMullis_2009.sph', 'KateOrff_2010W.sph', 'KatherineFulton_2007.sph', 'KeithBarry_2004.sph', 'KeithBellows_2002.sph', 'KeithSchachtandZachKaplan_2005.sph', 'KenKamler_2009P.sph', 'KevinBales_2010.sph', 'KevinKelly_2005.sph', 'KevinKelly_2007P.sph', 'KevinKelly_2009X.sph', 'KevinStone_2010U.sph', 'KevinSurace_2009.sph', 'KimGorgens_2010X.sph', 'KiranBedi_2010W.sph', 'KiranBirSethi_2009I.sph', 'KirkCitron_2010.sph', 'KRamdas_2009I.sph', 'KristenAshburn_2003.sph', 'KristinaGjerde_2010Z.sph', 'KwabenaBoahen_2007G.sph', 'LakshmiPratury_2007.sph', 'LaliteshKattragadda_2009I.sph', 'LarryBrilliant_2006.sph', 'LarryBrilliant_2007P.sph', 'LarryBurns_2005.sph', 'LarryLessig_2007.sph', 'LauraTrice_2008.sph', 'LaurieGarrett_2007U.sph', 'LaurieSantos_2010G.sph', 'LawrenceLessig_2010X.sph', 'LeeHotz_2010G.sph', 'LeeSmolin_2003.sph', 'LennartGreen_2005.sph', 'LesleyHazleton_2010X.sph', 'LewisPugh_2009G.sph', 'LewisPugh_2010G.sph', 'LisaMargonelli_2010X.sph', 'list.txt', 'LizaDonnelly_2010W.sph', 'LizColeman_2009.sph', 'LizDiller_2007P.sph', 'LorettaNapoleoni_2009G.sph', 'LouiseFresco_2009.sph', 'LouiseLeakey_2008.sph', 'LucaTurin_2005.sph', 'MaeJemison_2002.sph', 'MagnusLarsson_2009G.sph', 'MairaKalman_2007.sph', 'MajoraCarter_2006.sph', 'MajoraCarter_2010X.sph', 'MalcolmGladwell_2004.sph', 'MallikaSarabhai_2009I.sph', 'MarcelDicke_2010G.sph', 'MarcKoska_2009G.sph', 'MarcPachter_2008P.sph', 'MarcusduSautoy_2009G.sph', 'MargaretStewart_2010U.sph', 'MargaretWertheim_2009.sph', 'MarianBantjes_2010.sph', 'MarisaFickJordan_2007G2.sph', 'MarkBittman_2007P.sph', 'MarkRoth_2010.sph', 'MartinJacques_2010S.sph', 'MartinRees_2005G.sph', 'MarvinMinsky_2003.sph', 'MaryRoach_2009.sph', 'MathieuLehanneur_2009G.sph', 'MatthewChilds_2009U.sph', 'MatthieuRicard_2004.sph', 'MattRidley_2010G.sph', 'MazJobrani_2010G.sph', 'MechaiViravaidya_2010X.sph', 'MelindaGates_2010X.sph', 'MenaTrott_2006.sph', 'MichaelMerzenich_2004.sph', 'MichaelMilken_2001.sph', 'MichaelMoschen_2002.sph', 'MichaelPollan_2007.sph', 'MichaelPritchard_2009G.sph', 'MichaelSandel_2010.sph', 'MichaelShermer_2006.sph', 'MichaelShermer_2010.sph', 'MichelleObama_2009P.sph', 'MihalyCsikszentmihalyi_2004.sph', 'MikedeGruy_2010Z.sph', 'MikeRowe_2008P.sph', 'MiltonGlaser_1998.sph', 'MiruKim_2008P.sph', 'MishaGlenny_2009G.sph', 'MitchellJoachim_2010.sph', 'MosheSafdie_2002.sph', 'MurrayGellMann_2007.sph', 'MurrayGellMannLANGUAGE_2007.sph', 'NaifAlMutawa_2010G.sph', 'NaliniNadkarni_2009.sph', 'NaliniNadkarni_2010U.sph', 'name.bat', 'NancyEtcoff_2004.sph', 'NandanNilekani_2009.sph', 'NaomiKlein_2010W.sph', 'NatalieJeremijenko_2009P.sph', 'NatalieMerchant_2010.sph', 'NatashaTsakos_2009.sph', 'NateSilver_2009.sph', 'NathanielKahn_2002.sph', 'NathanMyhrvold_2007.sph', 'NathanMyhrvold_2010.sph', 'NathanWolfe_2009.sph', 'Naturally7FLYBABY_2009.sph', 'NeilGershenfeld_2006.sph', 'NeilPasricha_2010X.sph', 'NeilTurok_2008.sph', 'NellieMcKayCLONIE_2008.sph', 'NellieMcKayFEMINISTSIF_2008.sph', 'NellieMcKayTHEDOGSONG_2008.sph', 'NewtonAduaka_2007G.sph', 'NgoziOkonjoIweala_2007.sph', 'NgoziOkonjoIweala_2007G.sph', 'NicholasChristakis_2010.sph', 'NicholasChristakis_2010S.sph', 'NicholasNegroponte_1984.sph', 'NicholasNegroponte_2006.sph', 'NicholasNegroponte_2007P.sph', 'NicholasNegroponte_2008.sph', 'NickBostrom_2005G.sph', 'NickSears_2007.sph', 'NickVeasey_2009G.sph', 'NicMarks_2010G.sph', 'NielsDiffrient_2002a.sph', 'NinaJablonski_2009.sph', 'NoahFeldman_2003.sph', 'NoraYorkWHATIWANT_2006S.sph', 'NormanFoster_2007P.sph', 'NuclearDebate_2010.sph', 'OlafurEliasson_2009.sph', 'OliverSacks_2009.sph', 'OmarAhmad_2010U.sph', 'OryOkolloh_2007G.sph', 'PameliaKurstin_2002.sph', 'PaolaAntonelli_2007.sph', 'PaolaAntonelli_2007P.sph', 'ParagKhanna_2009G.sph', 'PatriciaBurchat_2008.sph', 'PatrickAwuah_2007G.sph', 'PatrickChappatte_2010G.sph', 'PattieMaes_2009.sph', 'PaulaScher_2008P.sph', 'PaulBennett_2005G.sph', 'PaulCollier_2008.sph', 'PaulCollier_2009S.sph', 'PaulDebevec_2009X.sph', 'PaulEwald_2007.sph', 'PaulMacCready_1998.sph', 'PaulMacCready_2003.sph', 'PaulMoller_2004.sph', 'PaulRomer_2009G.sph', 'PaulRothemund_2007.sph', 'PaulRothemund_2008.sph', 'PaulSereno_2005.sph', 'PaulStamets_2008.sph', 'PawanSinha_2009I.sph', 'PenelopeBoston_2006.sph', 'PeterDiamandis_2005G.sph', 'PeterDiamandis_2008.sph', 'PeterDonnelly_2005G.sph', 'PeterEigen_2009X.sph', 'PeterGabriel_2006.sph', 'PeterHaas_2010G.sph', 'PeterHirshberg_2007P.sph', 'PeterMolyneux_2010G.sph', 'PeterReinhart_2008P.sph', 'PeterTyack_2010Z.sph', 'PeterWard_2008.sph', 'PhilBorges_2006.sph', 'PhilipHoward_2010.sph', 'PhilippeStarck_2007.sph', 'PhilipRosedale_2008P.sph', 'PhilZimbardo_2008.sph', 'PhilZimbardo_2009U.sph', 'PranavMistry_2009I.sph', 'PWSinger_2009.sph', 'RachelArmstrong_2009G.sph', 'RachelBotsman_2010X.sph', 'RachelPike_2009G.sph', 'RachelSussman_2010G.sph', 'RaghavaKK_2010.sph', 'RAMashelkar_2009I.sph', 'RaulMidonANSWERS_2007.sph', 'RaulMidonEVERYBODY_2007.sph', 'RavinAgrawal_2009I.sph', 'RayAnderson_2009.sph', 'RayKurzweil_2005.sph', 'RayKurzweil_2009U.sph', 'RayZahab_2009.sph', 'RebeccaSaxe_2009G.sph', 'ReedKroloff_2003.sph', 'RennyGleeson_2009.sph', 'RichardBaraniuk_2006.sph', 'RichardBranson_2007.sph', 'RichardDawkins_2002.sph', 'RichardDawkins_2005G.sph', 'RichardPreston_2008.sph', 'RichardPyle_2004.sph', 'RichardSears_2010U.sph', 'RichardSt.John_2005.sph', 'RichardStJohn_2009U.sph', 'RickSmolan_2007P.sph', 'RickWarren_2006.sph', 'Rives4AM_2007.sph', 'RivesINTERNET_2006S.sph', 'RivesMOCKINGBIRD_2006.sph', 'RivesTTYL_2008.sph', 'RobDunbar_2010Z.sph', 'RobertBallard_2008.sph', 'RobertFischell_2005.sph', 'RobertFull_2002.sph', 'RobertFull_2005.sph', 'RobertFull_2009.sph', 'RobertLang_2008.sph', 'RobertNeuwirth_2005.sph', 'RobertThurman_2009P.sph', 'RobertWright_2006.sph', 'RobertWright_2009P.sph', 'RobForbes_2006.sph', 'RobHopkins_2009G.sph', 'RobinChase_2007.sph', 'RodneyBrooks_2003.sph', 'RomulusWhitaker_2009I.sph', 'RonEglash_2007G2.sph', 'RoryBremner_2009G.sph', 'RorySutherland_2009G.sph', 'RorySutherland_2010S.sph', 'RossLovegrove_2005.sph', 'RoyGould_2008.sph', 'RozSavage_2010Z.sph', 'RufusGriscomandAlisaVolkman_2010W.sph', 'RyanLobo_2009I.sph', 'SamanthaPower_2008.sph', 'SamHarris_2010.sph', 'SamMartin_2009G.sph', 'SarahJones_2009.sph', 'Saraswati_2009P.sph', 'SasaVucinic_2005G.sph', 'SaulGriffith_2009.sph', 'ScottKim_2008P.sph', 'ScottMcCloud_2005.sph', 'SeanGourley_2009U.sph', 'SebastianSeung_2010G.sph', 'SebastianWernicke_2010A.sph', 'SendhilMullainathan_2009I.sph', 'SergeyBrin_2004.sph', 'SethBerkley_2010.sph', 'SethGodin_2003.sph', 'SethGodin_2009.sph', 'SethPriebatsch_2010X.sph', 'SeyiOyesola_2007G.sph', 'ShaffiMather_2009I.sph', 'ShaiAgassi_2009.sph', 'SharmeenObaidChinoy_2010U.sph', 'ShashiTharoor_2009I.sph', 'SheenaIyengar_2010G.sph', 'SheilaPatek_2004.sph', 'ShekharKapur_2009I.sph', 'ShereenElFeki_2009G.sph', 'SherwinNuland_2001.sph', 'SherwinNuland_2003.sph', 'SherylSandberg_2010W.sph', 'SherylWuDunn_2010G.sph', 'ShimonSchocken_2010X.sph', 'ShimonSteinberg_2010X.sph', 'ShuklaBose_2009I.sph', 'SiegfriedWoldhek_2008.sph', 'SimonSinek_2009X.sph', 'SirenaHuang_2006.sph', 'SirKenRobinson_2006.sph', 'SirKenRobinson_2010.sph', 'SophalEar_2009U.sph', 'SpencerWells_2007G.sph', 'StaceyKramer_2010.sph', 'StefanaBroadbent_2009G.sph', 'StefanoMancuso_2010G.sph', 'StefanSagmeister_2004.sph', 'StefanSagmeister_2008.sph', 'StefanSagmeister_2009G.sph', 'StefanWolff_2010G.sph', 'StephenHawking_2008.sph', 'StephenLawler_2007.sph', 'StephenPalumbi_2010Z.sph', 'StephenPetranek_2002.sph', 'StephenWolfram_2010.sph', 'SteveJurvetson_2007.sph', 'StevenCowley_2009G.sph', 'StevenJohnson_2003.sph', 'StevenJohnson_2006S.sph', 'StevenJohnson_2010G.sph', 'StevenLevitt_2004.sph', 'StevenLevitt_2005G.sph', 'StevenPinker_2003.sph', 'StevenPinker_2005G.sph', 'StevenPinker_2007.sph', 'StevenStrogatz_2004R.sph', 'SteveTruglia_2009G.sph', 'StewartBrand_2004.sph', 'StewartBrand_2006.sph', 'StewartBrand_2009S.sph', 'StewBLACKMENSKI_2006.sph', 'StuartBrown_2008P.sph', 'SugataMitra_2007P.sph', 'SugataMitra_2010G.sph', 'SuheirHammad_2010W.sph', 'SunithaKrishnan_2009I.sph', 'SusanBlackmore_2008.sph', 'SusanSavageRumbaugh_2004.sph', 'SusanShaw_2010X.sph', 'SylviaEarle_2009.sph', 'TanLe_2010G.sph', 'TarynSimon_2009G.sph', 'TempleGrandin_2010.sph', 'TeresaCarrenoOrchestra_2009.sph', 'ThelmaGolden_2009.sph', 'TheLXD_2010.sph', 'TheoJansen_2007.sph', 'TheRaspyniBrothers_2002.sph', 'TheyMightBeGiants_2007.sph', 'ThomasBarnett_2005.sph', 'ThomasDolby_2010.sph', 'ThomasDolbyandRachelleGarniezLAVIEENROSE_2004.sph', 'ThomasGoetz_2010P.sph', 'ThomasThwaites_2010S.sph', 'ThomMayne_2005.sph', 'ThulasirajRavilla_2009I.sph', 'TierneyThys_2003.sph', 'TimBernersLee_2009.sph', 'TimBernersLee_2010U.sph', 'TimBrown_2008P.sph', 'TimBrown_2009G.sph', 'TimFerriss_2008P.sph', 'TimJackson_2010G.sph', 'TodMachover_2008.sph', 'TomChatfield_2010G.sph', 'TomHoney_2005.sph', 'TomRielly_2006.sph', 'TomShannon_2003.sph', 'TomShannon_2009S.sph', 'TomWujec_2009GU.sph', 'TomWujec_2009U.sph', 'TonyPorter_2010W.sph', 'TonyRobbins_2006.sph', 'TorstenReil_2003.sph', 'UeliGegenschatz_2009.sph', 'UrsusWehrli_2006.sph', 'VanJones_2010X.sph', 'VikMuniz_2003.sph', 'VilayanurRamachandran_2007.sph', 'VilayanurRamachandran_2009I.sph', 'VirginiaPostrel_2004.sph', 'VusiMahlaselaSONGOFMAMA_2007G.sph', 'WadeDavis_2008.sph', 'WillardWigan_2009G.sph', 'WilliamKamkwamba_2007G.sph', 'WilliamKamkwamba_2009G.sph', 'WilliamLi_2010.sph', 'WilliamMcDonough_2005.sph', 'WilliamUry_2010X.sph', 'WillieSmits_2009.sph', 'WillWright_2007.sph', 'WoodyNorris_2004.sph', 'XDRTB_2008.sph', 'YannArthusBertrand_2009.sph', 'YochaiBenkler_2005G.sph', 'YossiVardi_2007.sph', 'YvesBehar_2008.sph', 'YvesBehar_2009.sph', 'ZainabSalbi_2010G.sph', 'ZeFrank_2004.sph', 'ZeFrank_2010G.sph', 'ZeresenayAlemseged_2007G.sph']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "old_data=[]\n",
        "feature_list=[]\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/term project/after_syanalysis_v2.csv', 'r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    feature_list=next(csv_reader)\n",
        "    for row in csv_reader:\n",
        "        old_data.append(row)\n",
        "#add_feature=['mean_Yngve_depth','total_Yngve_depth','max_Yngve_depth','mean_left_branching','total_left_branching','max_left_branching']\n",
        "#add_feature=['num_coreferences','mean_coreferences_length']\n",
        "#for i in range(0,len(add_feature)):\n",
        "#  feature_list.append(add_feature[i])\n",
        "print(feature_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O0XIb-Dl1xd",
        "outputId": "a7d66a41-07e3-4610-b09c-94eb9862c88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['name', 'words_number', 'SPACE', 'ADV', 'VERB', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'INTJ', 'NUM', 'PRON', 'AUX', 'CCONJ', 'PART', 'PROPN', 'SCONJ', 'CONJ', 'Punctuation', 'hestitation_word', 'lemma_number', 'most_frequent', 'noun_chunk', 'person_singular_verbs', 'misspell', 'time_spec', 'spec', 'sentence', 'neg_word', 'content', 'function', 'SPACE_R', 'ADV_R', 'VERB_R', 'ADP_R', 'DET_R', 'NOUN_R', 'ADJ_R', 'PUNCT_R', 'INTJ_R', 'NUM_R', 'PRON_R', 'AUX_R', 'CCONJ_R', 'PART_R', 'PROPN_R', 'SCONJ_R', 'CONJ_R', 'Punctuation_R', 'hestitation_word_R', 'lemma_number_R', 'person_singular_verbs_R', 'misspell_R', 'time_spec_R', 'spec_R', 'neg_word_R', 'content_R', 'function_R', 'time_split', 'wordnum_t', 'SPACE_t', 'ADV_t', 'VERB_t', 'ADP_t', 'DET_t', 'NOUN_t', 'ADJ_t', 'PUNCT_t', 'INTJ_t', 'NUM_t', 'PRON_t', 'AUX_t', 'CCONJ_t', 'PART_t', 'PROPN_t', 'SCONJ_t', 'CONJ_t', 'Punctuation_t', 'hestitation_word_t', 'lemma_number_t', 'most_frequent_t', 'noun_chunk_t', 'person_singular_verbs_t', 'misspell_t', 'time_spec_t', 'spec_t', 'sentence_t', 'neg_word_t', 'content_t', 'function_t', 'mean_ttr', 'total_ttr', 'max_ttr', 'mean_mattr', 'total_mattr', 'max_mattr', 'mean_brunet_index', 'total_brunet_index', 'max_brunet_index', 'mean_honore_statistic', 'total_honore_statistic', 'max_honore_statistic', 'good_emoji', 'no_emoji', 'bad_emoji', 'mean_sdl', 'total_sdl', 'max_sdl', 'mean_Yngve_depth', 'total_Yngve_depth', 'max_Yngve_depth', 'mean_left_branching', 'total_left_branching', 'max_left_branching', 'frazer_chunk', 'max_frazer_depth', 'mean_frazer', 'cosine_dis', 'repeat_rate', 'average_frequency', 'average_frequency_subtlw', 'mean_clause', 'mean_t_unit', 'mean_dependency_tree_height', 'mex_dependency_tree_height', 'mean_parser_tree_height', 'mex_parser_tree_height']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert to lowercase and remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
        "    return text\n",
        "\n",
        "def calculate_cosine_distance(utterances):\n",
        "    # Preprocess the utterances\n",
        "    preprocessed_utterances = [preprocess_text(utterance) for utterance in utterances]\n",
        "\n",
        "    # Create a bag-of-words representation\n",
        "    vectorizer = CountVectorizer(stop_words=stopwords.words('english'))\n",
        "    X = vectorizer.fit_transform(preprocessed_utterances)\n",
        "\n",
        "    # Calculate cosine distances\n",
        "    cosine_distances_matrix = cosine_distances(X)\n",
        "\n",
        "    return cosine_distances_matrix\n",
        "\n",
        "def detect_repetitive_content(utterances, threshold=0.2):\n",
        "    # Calculate cosine distances\n",
        "    cosine_distances_matrix = calculate_cosine_distance(utterances)\n",
        "\n",
        "    # Measure average distance\n",
        "    average_distance = cosine_distances_matrix.mean()\n",
        "\n",
        "    # Measure the proportion of utterance pairs below the threshold\n",
        "    below_threshold_count = (cosine_distances_matrix < threshold).sum()\n",
        "    total_pairs = len(utterances) * (len(utterances) - 1) // 2\n",
        "    proportion_below_threshold = below_threshold_count / total_pairs\n",
        "\n",
        "    return average_distance, proportion_below_threshold"
      ],
      "metadata": {
        "id": "YPSjEd7LcrIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_clauses(sentence):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(sentence)\n",
        "    clauses = []\n",
        "    for token in doc:\n",
        "        if \"subj\" in token.dep_ or \"obj\" in token.dep_:\n",
        "            clause_tokens = [t.text for t in token.subtree]\n",
        "            clauses.append(\" \".join(clause_tokens))\n",
        "    return clauses\n",
        "def mean_clause_length(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    mean_clauses = []\n",
        "    for sentence in sentences:\n",
        "      clauses = extract_clauses(sentence)\n",
        "      clause_lengths = [len(clause.split()) for clause in clauses]\n",
        "      if clause_lengths:\n",
        "          mean_length = sum(clause_lengths) / len(clause_lengths)\n",
        "          mean_clauses.append(mean_length)\n",
        "    return statistics.mean(mean_clauses)\n",
        "sentence = \"A semantic impairment may manifest in an increased reliance on highly familiar words.\"\n",
        "mean_length = mean_clause_length(sentence)\n",
        "print(\"Mean Length of Clauses:\", mean_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYLBKY-01A_B",
        "outputId": "72ecee7f-f861-485d-b119-510bdc866753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Length of Clauses: 4.333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def familiar(text):\n",
        "  subtlex_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/term project/subtex_data.csv')\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  subtlex_data['Word']=subtlex_data['Word'].str.lower()\n",
        "  filtered_data = subtlex_data[subtlex_data['Word'].isin(tokens)]\n",
        "  average_frequency = filtered_data['FREQcount'].mean()\n",
        "  average_frequency_subtlw = filtered_data['SUBTLWF'].mean()\n",
        "  return average_frequency,average_frequency_subtlw\n"
      ],
      "metadata": {
        "id": "CqZAi7mseJSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "def calculate_t_unit_length(text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    mean_t_unit = []\n",
        "    for sentence in sentences:\n",
        "      doc = nlp(sentence)\n",
        "      t_units = []\n",
        "      for sent in doc.sents:\n",
        "          if any(token.head == token for token in sent):\n",
        "              t_units.append(len(sent))\n",
        "      if(len(t_units)>0):\n",
        "        mean_t_unit.append(sum(t_units) / len(t_units))\n",
        "    return statistics.mean(mean_t_unit)\n",
        "sentence = \"A semantic impairment may manifest in an increased reliance on highly familiar words.\"\n",
        "mean_t_unit_length = calculate_t_unit_length(sentence)\n",
        "print(\"Mean T-unit Length:\", mean_t_unit_length)"
      ],
      "metadata": {
        "id": "YvhN7gkl7sg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1aba57-38f4-4afb-bd29-c1efd79aa45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean T-unit Length: 14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma,depparse')\n",
        "def get_parse_tree_height(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    parse_tree_height = []\n",
        "    for sentence in sentences:\n",
        "      doc = nlp(sentence)\n",
        "      parse_tree_height.append(max(word.head for sent in doc.sentences for word in sent.words))\n",
        "    return parse_tree_height"
      ],
      "metadata": {
        "id": "RSoGN2RtUf8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_coreferences_stanza(text):\n",
        "    nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma,ner,coref')\n",
        "    doc = nlp(text)\n",
        "    # Access coreference clusters\n",
        "    coref_clusters = doc.coref\n",
        "\n",
        "    # Count the number of coreferences and calculate mean length\n",
        "    total_length = 0\n",
        "    num_coreferences = len(coref_clusters)\n",
        "\n",
        "    for cluster in coref_clusters:\n",
        "        total_length += len(cluster)\n",
        "\n",
        "    mean_coreferences_length = total_length / num_coreferences if num_coreferences > 0 else 0\n",
        "\n",
        "    return num_coreferences, mean_coreferences_length\n",
        "sentence = \"A semantic impairment may manifest in an increased reliance on highly familiar words.\"\n",
        "coreferences = analyze_coreferences_stanza(sentence)\n",
        "print(\"analyze_coreferences_stanza:\", coreferences)"
      ],
      "metadata": {
        "id": "xi8QX7RX4cpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_dependency_tree_height(text):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  dependency_height = []\n",
        "  for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    root = next(token for token in doc if token.head == token)\n",
        "    def calculate_height(token):\n",
        "        if not list(token.children):\n",
        "            return 1\n",
        "        else:\n",
        "            return 1 + max(calculate_height(child) for child in token.children)\n",
        "    dependency_height.append(calculate_height(root))\n",
        "  return dependency_height\n",
        "sentence = \"A semantic impairment may manifest in an increased reliance on highly familiar words.\"\n",
        "\n",
        "# Get the dependency tree height from the sentence\n",
        "tree_height = calculate_dependency_tree_height(sentence)\n",
        "\n",
        "# Print the result\n",
        "print(\"Dependency Tree Height:\", tree_height)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmRpuETiEO_q",
        "outputId": "9088e65e-a915-47ec-97eb-595535d77129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependency Tree Height: [7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "stanza.download('en', processors='coref')\n",
        "nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma,ner,coref')"
      ],
      "metadata": {
        "id": "UyfkJSRd9sWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/term project/after_syanalysis_v2.csv')\n",
        "# Find rows where a specific column (e.g., 'Column1') has empty values\n",
        "empty_rows = df[df['mex_parser_tree_height']==0]\n",
        "empty_row_names = empty_rows.index.tolist()\n",
        "print(empty_row_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH0kfKRHkNF3",
        "outputId": "b6dd0d74-25be-4338-dd71-17a5864e2328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[65, 67, 83, 91, 101, 130, 160, 161, 164, 229, 234, 244, 247, 269, 286, 301, 304, 334, 335, 340, 347, 372, 391, 409, 422, 433, 482, 487, 504, 527, 534, 584, 658, 659, 669, 686, 716, 722, 738, 755, 764]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(empty_row_names)):\n",
        "  #try:\n",
        "    print(filenames[empty_row_names[i]])\n",
        "    source_file_path='/content/drive/MyDrive/Colab Notebooks/term project/TED text/'+filenames[empty_row_names[i]][0:len(filenames[empty_row_names[i]])-4]+'.txt'\n",
        "    f1 = open(source_file_path, \"r\")\n",
        "    line1 = f1.readline()\n",
        "    f1.close()\n",
        "    sentences = nltk.sent_tokenize(line1)\n",
        "    average_distance, proportion_below_threshold=detect_repetitive_content(sentences)\n",
        "    average_frequency,average_frequency_subtlw=familiar(line1)\n",
        "    mean_clause=mean_clause_length(line1)\n",
        "    mean_t_unit=calculate_t_unit_length(line1)\n",
        "    dependency_tree_height=calculate_dependency_tree_height(line1)\n",
        "    parse_tree_height=get_parse_tree_height(line1)\n",
        "    for j in range(0,len(old_data)):\n",
        "      if(old_data[j][0]==filenames[i]):\n",
        "        old_data[j][feature_list.index('cosine_dis')]=average_distance\n",
        "        old_data[j][feature_list.index('repeat_rate')]=proportion_below_threshold\n",
        "        old_data[j][feature_list.index('average_frequency')]=average_frequency\n",
        "        old_data[j][feature_list.index('average_frequency_subtlw')]=average_frequency_subtlw\n",
        "        old_data[j][feature_list.index('mean_clause')]=mean_clause\n",
        "        old_data[j][feature_list.index('mean_t_unit')]=mean_t_unit\n",
        "        old_data[j][feature_list.index('mean_dependency_tree_height')]=np.mean(dependency_tree_height)\n",
        "        old_data[j][feature_list.index('mex_dependency_tree_height')]=np.max(dependency_tree_height)\n",
        "        old_data[j][feature_list.index('mean_parser_tree_height')]=np.mean(parse_tree_height)\n",
        "        old_data[j][feature_list.index('mex_parser_tree_height')]=np.max(parse_tree_height)\n",
        "        print(\"complete\",filenames[empty_row_names[i]])\n",
        "        print(\"complete!!!!!\")\n",
        "        break\n",
        "  #except:\n",
        "    #print(\"fail in\",filenames[i])\n",
        "    #continue"
      ],
      "metadata": {
        "id": "xGr1F03Rmacy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def calculate_sdl(sentence):\n",
        "    # Parse the sentence\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Initialize a list to store SDLs for each dependency relationship\n",
        "    sdl_list = []\n",
        "\n",
        "    # Iterate over tokens in the sentence\n",
        "    for token in doc:\n",
        "        # Check if the token has a head and the relationship is not punctuation\n",
        "        if token.head is not token and token.dep_ not in ('punct', 'punct|conj'):\n",
        "            # Calculate SDL as the absolute difference in word indices\n",
        "            sdl = abs(token.i - token.head.i)\n",
        "            sdl_list.append(sdl)\n",
        "\n",
        "    return sdl_list\n",
        "\n",
        "# Example usage:\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "sdl_values = calculate_sdl(sentence)\n",
        "\n",
        "# Print the SDL values for each dependency relationship\n",
        "print(\"SDL Values:\", sdl_values)\n",
        "print(\"Mean SDL:\", sum(sdl_values) / len(sdl_values) if sdl_values else 0)\n",
        "print(\"Total SDL:\", sum(sdl_values))\n",
        "print(\"Maximum SDL:\", max(sdl_values) if sdl_values else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILQtKFhFbouM",
        "outputId": "8f8c457e-7470-40b2-8da9-f19b638ade1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDL Values: [3, 2, 1, 1, 0, 1, 2, 1, 3]\n",
            "Mean SDL: 1.5555555555555556\n",
            "Total SDL: 14\n",
            "Maximum SDL: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsXzifna85qK",
        "outputId": "a5064ab8-e888-4f8e-cc37-e236ecffc20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['name', 'words_number', 'SPACE', 'ADV', 'VERB', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'INTJ', 'NUM', 'PRON', 'AUX', 'CCONJ', 'PART', 'PROPN', 'SCONJ', 'CONJ', 'Punctuation', 'hestitation_word', 'lemma_number', 'most_frequent', 'noun_chunk', 'person_singular_verbs', 'misspell', 'time_spec', 'spec', 'sentence', 'neg_word', 'content', 'function', 'SPACE_R', 'ADV_R', 'VERB_R', 'ADP_R', 'DET_R', 'NOUN_R', 'ADJ_R', 'PUNCT_R', 'INTJ_R', 'NUM_R', 'PRON_R', 'AUX_R', 'CCONJ_R', 'PART_R', 'PROPN_R', 'SCONJ_R', 'CONJ_R', 'Punctuation_R', 'hestitation_word_R', 'lemma_number_R', 'person_singular_verbs_R', 'misspell_R', 'time_spec_R', 'spec_R', 'neg_word_R', 'content_R', 'function_R', 'time_split', 'wordnum_t', 'SPACE_t', 'ADV_t', 'VERB_t', 'ADP_t', 'DET_t', 'NOUN_t', 'ADJ_t', 'PUNCT_t', 'INTJ_t', 'NUM_t', 'PRON_t', 'AUX_t', 'CCONJ_t', 'PART_t', 'PROPN_t', 'SCONJ_t', 'CONJ_t', 'Punctuation_t', 'hestitation_word_t', 'lemma_number_t', 'most_frequent_t', 'noun_chunk_t', 'person_singular_verbs_t', 'misspell_t', 'time_spec_t', 'spec_t', 'sentence_t', 'neg_word_t', 'content_t', 'function_t', 'mean_ttr', 'total_ttr', 'max_ttr', 'mean_mattr', 'total_mattr', 'max_mattr', 'mean_brunet_index', 'total_brunet_index', 'max_brunet_index', 'mean_honore_statistic', 'total_honore_statistic', 'max_honore_statistic', 'good_emoji', 'no_emoji', 'bad_emoji', 'mean_sdl', 'total_sdl', 'max_sdl', 'mean_Yngve_depth', 'total_Yngve_depth', 'max_Yngve_depth', 'mean_left_branching', 'total_left_branching', 'max_left_branching', 'frazer_chunk', 'max_frazer_depth', 'mean_frazer', 'cosine_dis', 'repeat_rate', 'average_frequency', 'average_frequency_subtlw']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/term project/after_syanalysis_v3.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  writer.writerow(feature_list)\n",
        "  for i in range(0,len(old_data)):\n",
        "    writer.writerow(old_data[i])"
      ],
      "metadata": {
        "id": "OApdX2lJo77w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}