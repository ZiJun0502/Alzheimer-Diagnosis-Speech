{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3ULxWjyloQpM"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    141\u001b[0m     data_integration \u001b[38;5;241m=\u001b[39m DataMerge(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmfcc.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerge.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m     \u001b[43mdata_integration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mDataMerge.merge\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m mfcc_df\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m#merge txt and mfcc\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m merged_input_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtxt_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m merged_input_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAD_diagnose\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(patient_info\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# drop certain cols\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m rk \u001b[38;5;241m=\u001b[39m cast(Hashable, rk)\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1162\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import LearningModel_obj as Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def predict(x, y_true, model):\n",
    "    \"\"\"make prediction and calculate accuracy\"\"\"\n",
    "\n",
    "    # make prediction\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)  # Calculate Accuracy\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)  # Calculate MCC\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Calculate F1-score\n",
    "\n",
    "    print('- Accuracy: %s' % accuracy)\n",
    "    print('- MCC: %s' % mcc)\n",
    "    print('- F1 score: %s' % f1)\n",
    "\n",
    "\n",
    "#MFCC data extraction\n",
    "class data_process:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.labels = []\n",
    "        self.mean_features = []\n",
    "        self.std_features = []\n",
    "        self.var_features = []\n",
    "        self.min_features = []\n",
    "        self.max_features = []\n",
    "\n",
    "    def cal_mfcc_features(self, df):\n",
    "        self.mean_features.append(df.mean(axis=0))  # mean value of each frame\n",
    "        self.std_features.append(\n",
    "            df.std(axis=0))  # standard deviation of each frame\n",
    "        self.var_features.append(df.var(axis=0))  # variance of each frame\n",
    "        self.min_features.append(df.min(axis=0))  # minimum of each frame\n",
    "        self.max_features.append(df.max(axis=0))  # maximum of each frame\n",
    "\n",
    "\n",
    "class DataMerge():\n",
    "    \n",
    "    \"\"\"Input file path, this class will read in files and output a merged one \"\"\"\n",
    "    \n",
    "    def  __init__(self, NLP_input, mfcc_input, merged_data):\n",
    "        self.nlp_path = NLP_input\n",
    "        self.mfcc_path = mfcc_input\n",
    "        self.final_path = merged_data\n",
    "\n",
    "    def merge(self):\n",
    "        txt_df = pd.read_csv(self.nlp_path)\n",
    "\n",
    "        dp = data_process()\n",
    "\n",
    "        #read in mfcc file\n",
    "        aud_df = pd.read_csv(self.mfcc_path, header=None)\n",
    "\n",
    "        audio_names = [\"tmp\"]\n",
    "        mean_names = [\n",
    "            \"mean_0\", \"mean_1\", \"mean_2\", \"mean_3\", \"mean_4\", \"mean_5\", \"mean_6\",\n",
    "            \"mean_7\", \"mean_8\", \"mean_9\", \"mean_10\", \"mean_11\"\n",
    "        ]\n",
    "        std_names = [\n",
    "            \"std_0\", \"std_1\", \"std_2\", \"std_3\", \"std_4\", \"std_5\", \"std_6\", \"std_7\",\n",
    "            \"std_8\", \"std_9\", \"std_10\", \"std_11\"\n",
    "        ]\n",
    "        var_names = [\n",
    "            \"var_0\", \"var_1\", \"var_2\", \"var_3\", \"var_4\", \"var_5\", \"var_6\", \"var_7\",\n",
    "            \"var_8\", \"var_9\", \"var_10\", \"var_11\"\n",
    "        ]\n",
    "        min_names = [\n",
    "            \"min_0\", \"min_1\", \"min_2\", \"min_3\", \"min_4\", \"min_5\", \"min_6\", \"min_7\",\n",
    "            \"min_8\", \"min_9\", \"min_10\", \"min_11\"\n",
    "        ]\n",
    "        max_names = [\n",
    "            \"max_0\", \"max_1\", \"max_2\", \"max_3\", \"max_4\", \"max_5\", \"max_6\", \"max_7\",\n",
    "            \"max_8\", \"max_9\", \"max_10\", \"max_11\"\n",
    "        ]\n",
    "\n",
    "        dp.cal_mfcc_features(aud_df)\n",
    "\n",
    "        mean_df = pd.DataFrame(dp.mean_features)\n",
    "        mean_df.columns = mean_names\n",
    "        mean_df[\"name\"] = audio_names\n",
    "        mean_df = mean_df.reindex([\n",
    "            \"name\", \"mean_0\", \"mean_1\", \"mean_2\", \"mean_3\", \"mean_4\", \"mean_5\",\n",
    "            \"mean_6\", \"mean_7\", \"mean_8\", \"mean_9\", \"mean_10\", \"mean_11\"\n",
    "        ], axis=1)\n",
    "\n",
    "        std_df = pd.DataFrame(dp.std_features)\n",
    "        std_df.columns = std_names\n",
    "        std_df[\"name\"] = audio_names\n",
    "\n",
    "        var_df = pd.DataFrame(dp.var_features)\n",
    "        var_df.columns = var_names\n",
    "        var_df[\"name\"] = audio_names\n",
    "\n",
    "        min_df = pd.DataFrame(dp.min_features)\n",
    "        min_df.columns = min_names\n",
    "        min_df[\"name\"] = audio_names\n",
    "\n",
    "        max_df = pd.DataFrame(dp.max_features)\n",
    "        max_df.columns = max_names\n",
    "        max_df[\"name\"] = audio_names\n",
    "\n",
    "        mfcc_df = pd.merge(mean_df, std_df, how=\"right\", on=\"name\")\n",
    "        mfcc_df = pd.merge(mfcc_df, var_df, how=\"right\", on=\"name\")\n",
    "        mfcc_df = pd.merge(mfcc_df, min_df, how=\"right\", on=\"name\")\n",
    "        mfcc_df = pd.merge(mfcc_df, max_df, how=\"right\", on=\"name\")\n",
    "        mfcc_df\n",
    "\n",
    "        #merge txt and mfcc\n",
    "        merged_input_df = pd.merge(mfcc_df, txt_df, how=\"right\", on=\"name\")\n",
    "        merged_input_df[\"AD_diagnose\"] = np.ones(patient_info.shape[0], dtype=int)\n",
    "\n",
    "        # drop certain cols\n",
    "        drop_cols = [\n",
    "            'SPACE', 'ADV', 'VERB', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'INTJ',\n",
    "            'NUM', 'PRON', 'AUX', 'CCONJ', 'PART', 'PROPN', 'SCONJ', 'CONJ',\n",
    "            'Punctuation', 'hestitation_word', 'lemma_number', 'most_frequent',\n",
    "            'noun_chunk', 'person_singular_verbs', 'misspell', 'time_spec', 'spec',\n",
    "            'sentence', 'neg_word', 'content', 'function', 'function_R'\n",
    "        ]\n",
    "        merged_input_df = merged_input_df.drop(drop_cols, axis=1)\n",
    "\n",
    "        for i in range(merged_input_df.shape[0]):  #traverse all rows in merged input\n",
    "            if (merged_input_df[\"label\"][i] == 0):\n",
    "                merged_input_df.at[i, \"AD_diagnose\"] = 2\n",
    "\n",
    "        merged_input_df.to_csv(self.final_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_integration = DataMerge(\"nlp.csv\", \"mfcc.csv\", \"merge.csv\")\n",
    "    data_integration.merge()\n",
    "#     #build model, make prediction\n",
    "#     MCI_AD = \"mfcc.csv\"\n",
    "\n",
    "#     training_df = pd.read_csv(MCI_AD)\n",
    "\n",
    "#     X = training_df.drop(['name', 'AD_diagnose'], axis=1)\n",
    "#     y = training_df['AD_diagnose']\n",
    "\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.8, random_state=34)\n",
    "#     print(X_train.shape)\n",
    "#     print(X_val.shape)\n",
    "\n",
    "#     model = Model.Model(X_train, y_train)\n",
    "#     model.BaseLearner()\n",
    "#     model.StackModel()\n",
    "\n",
    "#     training_df = pd.read_csv('merged_input.csv')\n",
    "#     X = training_df.drop(['name', 'AD_diagnose'], axis=1)\n",
    "\n",
    "#     # predict(X_val, y_val, model.mlp)\n",
    "\n",
    "#     y_pred = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
