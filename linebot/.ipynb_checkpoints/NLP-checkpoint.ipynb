{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Messages from Ray:\n",
    "### 1. I've done the testing with the AdamSavage_2008P.txt file in this folder.\n",
    "###    The current version is still using the file path to read files. \n",
    "###    if any adjustments are needed, refer to the __init__ part of the class, the file should be taken as a input of the class initialization.\n",
    "###\n",
    "### 2. installing en_core_web_sm can take a while. And you might run into a weird error that says: \n",
    "###    OMP: Error #15: Initializing libiomp5.dylib, but found libomp.dylib already initialized.\n",
    "###    Try this if you encounter this problem: \n",
    "###        1. conda install nomkl\n",
    "###        2. python -m spacy download en\n",
    "###\n",
    "### 3. Comments are mostly written by me (Ray), which I am not very sure if I 100% understood the code correctly >_<'''\n",
    "###    Feel free to edit the comments :)\n",
    "###\n",
    "### 4. There is a sample output below, it seems like the function_R is missing? I'm not quite sure about it, I'll check with 宸宇\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import spacy\n",
    "from negspacy.negation import Negex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from negspacy.termsets import termset\n",
    "from negspacy.negation import Negex\n",
    "\n",
    "class NLP_features():\n",
    "    # Global attributes\n",
    "    nlp = en_core_web_sm.load()\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def __init__(self, file_handler):\n",
    "        self.file_handler = open(file_handler, \"r\")\n",
    "        self.word_dict = {}\n",
    "        self.feature_table = np.zeros(57)\n",
    "        self.words = 0\n",
    "\n",
    "    def doclen(self, line1):\n",
    "        ''' Analyzes the basic part of speech in the transript fed. The analyzation works line by line.\n",
    "            Input: A Sentence.\n",
    "            Output: \n",
    "        '''\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        return len(doc)\n",
    "    \n",
    "    def words_recognize(self, line1):\n",
    "        ''' Partition of each part of speech in the transript fed. The analyzation works line by line.\n",
    "            Input: A Sentence.\n",
    "            Output: Dictionary with part of speech as the key, list of words as the value -> {part of speech : [list of words]}\n",
    "        '''\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        # part of speech given\n",
    "        word_dic={}\n",
    "        pos_tag=['SPACE','ADV','VERB','ADP','DET','NOUN','ADJ','PUNCT','INTJ','NUM','PRON','AUX','CCONJ','PART','PROPN','SCONJ','X','CONJ','SYM']\n",
    "        for tag in pos_tag:\n",
    "            list1=[]\n",
    "            word_dic.update({tag:list1})\n",
    "        for token in doc:\n",
    "            word_dic[token.pos_].append(token.text)\n",
    "        return word_dic\n",
    "    def counting_lemma(self, line1):\n",
    "        ''' Counts the number of lemmas in a sentence. \n",
    "            Input: a Sentence\n",
    "            Output: \n",
    "        '''\n",
    "        lemma_dict={}\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        # Count token \n",
    "        for token in doc:\n",
    "            if(token.lemma_ not in lemma_dict):\n",
    "                lemma_dict.update({token.lemma_:1})\n",
    "            else:\n",
    "                lemma_dict[token.lemma_]+=1\n",
    "        sort_dict=dict(sorted(lemma_dict.items(), key=lambda item: item[1]))\n",
    "\n",
    "        max_freq =- 1\n",
    "        most_freq_words = \"none\"\n",
    "        for item in sort_dict:\n",
    "            if(sort_dict[item]>max_freq and item!='.' or item!=','):\n",
    "                max_freq=sort_dict[item]\n",
    "            most_freq_words=item\n",
    "\n",
    "        return len(lemma_dict), max_freq\n",
    "    \n",
    "    def counting_numnchunk(self, line1):\n",
    "        ''' Count the total number of nouns in a sentence\n",
    "            Input: A Sentence.\n",
    "            Output: total nouns in the sentence.\n",
    "        '''\n",
    "        num = 0\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        for chunk in doc.noun_chunks:\n",
    "            num+=1\n",
    "        return num\n",
    "    \n",
    "    def first_person_singular_verbs(self, line1):\n",
    "        ''' Count the total number of first person singular verbs in a sentence\n",
    "            Input: A sentence.\n",
    "            Output: total number of first person singular verbs.\n",
    "        '''\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        singular_verbs = 0\n",
    "        for i in range(0,len(doc)):\n",
    "            if(doc[i].pos_==\"VERB\"):\n",
    "                if(i>=1 and doc[i-1].text==\"I\"):\n",
    "                    singular_verbs+=1\n",
    "        return singular_verbs\n",
    "\n",
    "    def mis_spell(self, line1):\n",
    "        ''' Count the total number of misspelled words in a sentence\n",
    "            Input: A sentence.\n",
    "            Output: total number of misspelled words\n",
    "        '''\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        propn=[]\n",
    "        propnum=0\n",
    "        x_word=0\n",
    "\n",
    "        for token in doc:\n",
    "            if(token.pos_==\"PROPN\"):\n",
    "                propnum+=1\n",
    "            propn.append(token.text)\n",
    "\n",
    "        for token in doc:\n",
    "            if(token.pos_==\"X\" or token.pos_==\"SYM\"):\n",
    "                x_word+=1\n",
    "\n",
    "        real_propn=0\n",
    "        for ent in doc.ents:\n",
    "            if(ent.text in propn):\n",
    "                real_propn+=1\n",
    "        \n",
    "        return propnum + x_word-real_propn\n",
    "\n",
    "    def NES(self, line1):\n",
    "        ''' Count the absolute time term in a sentence.\n",
    "            Input: Sentence\n",
    "            Output: Count of absolute time term.\n",
    "        '''\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        time_term=0\n",
    "        term=0\n",
    "        for ent in doc.ents:\n",
    "            if(ent.label_==\"TIME\"):\n",
    "                time_term+=1\n",
    "            term+=1\n",
    "        return time_term,term\n",
    "    \n",
    "    def neg_analyze(self, line1):\n",
    "        ''' Find the number of negation words in a sentence\n",
    "            Input: Sentence\n",
    "            Output: Number of negation words\n",
    "        '''\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        negnum=0\n",
    "        for e in doc.ents:\n",
    "            negnum+=1\n",
    "        return negnum\n",
    "    \n",
    "    def content_function(self, line1):\n",
    "        ''' 虛實詞\n",
    "            Input: Sentence\n",
    "            Output: \n",
    "        '''\n",
    "        doc = NLP_features.nlp(line1)\n",
    "        content_num=0\n",
    "        content_exception=[\"no\", \"not\", \"never\", \"this\", \"that\", \"these\" ,\"those\",\"what\", \"where\", \"when\", \"how\" , \"why\"]\n",
    "        for token in doc:\n",
    "            if(token.pos_==\"NOUN\"or token.pos_==\"VERB\" or token.pos_==\"ADJ\" or token.pos_==\"ADV\"):\n",
    "                content_num+=1\n",
    "            else:\n",
    "                if(token.text in content_exception):\n",
    "                    content_num+=1\n",
    "        function_word=0\n",
    "        for token in doc:\n",
    "            if(token.pos_==\"AUX\" or token.pos_==\"ADP\" or token.pos_==\"DET\" or token.pos_==\"CONJ\" or token.pos_==\"CCONJ\" or token.pos_==\"SCONJ\" or token.pos_==\"PRON\"):\n",
    "                if(token.text not in content_exception):\n",
    "                    function_word+=1\n",
    "        return content_num, function_word\n",
    "\n",
    "    def generate_features(self):\n",
    "        # Convert transcritps into features\n",
    "        line1 = self.file_handler.readline()\n",
    "        self.words = self.doclen(line1)\n",
    "        self.word_dict = self.words_recognize(line1)\n",
    "        self.feature_table[0]= self.words\n",
    "        self.feature_table[1]=len(self.word_dict[\"SPACE\"])\n",
    "        self.feature_table[2]=len(self.word_dict[\"ADV\"])\n",
    "        self.feature_table[3]=len(self.word_dict[\"VERB\"])\n",
    "        self.feature_table[4]=len(self.word_dict[\"ADP\"])\n",
    "        self.feature_table[5]=len(self.word_dict[\"DET\"])\n",
    "        self.feature_table[6]=len(self.word_dict[\"NOUN\"])\n",
    "        self.feature_table[7]=len(self.word_dict[\"ADJ\"])\n",
    "        self.feature_table[8]=len(self.word_dict[\"PUNCT\"])\n",
    "        self.feature_table[9]=len(self.word_dict[\"INTJ\"])\n",
    "        self.feature_table[10]=len(self.word_dict[\"NUM\"])\n",
    "        self.feature_table[11]=len(self.word_dict[\"PRON\"])\n",
    "        self.feature_table[12]=len(self.word_dict[\"AUX\"])\n",
    "        self.feature_table[13]=len(self.word_dict[\"CCONJ\"])\n",
    "        self.feature_table[14]=len(self.word_dict[\"PART\"])\n",
    "        self.feature_table[15]=len(self.word_dict[\"PROPN\"])\n",
    "        self.feature_table[16]=len(self.word_dict[\"SCONJ\"])\n",
    "        self.feature_table[17]=len(self.word_dict[\"CONJ\"])\n",
    "        self.feature_table[18]=len(self.word_dict[\"PUNCT\"])\n",
    "        self.feature_table[19]=len(self.word_dict[\"INTJ\"])\n",
    "        self.feature_table[20],self.feature_table[21] = self.counting_lemma(line1)\n",
    "        self.feature_table[22] = self.counting_numnchunk(line1)\n",
    "        self.feature_table[23] = self.first_person_singular_verbs(line1)\n",
    "        self.feature_table[24] = self.mis_spell(line1)\n",
    "        self.feature_table[25],self.feature_table[26] = self.NES(line1)\n",
    "        self.feature_table[27]= len(line1.split('.'))\n",
    "        self.feature_table[28] = self.neg_analyze(line1)\n",
    "        self.feature_table[29],self.feature_table[30] = self.content_function(line1)\n",
    "        self.feature_table[31]=len(self.word_dict[\"SPACE\"]) / self.words\n",
    "        self.feature_table[32]=len(self.word_dict[\"ADV\"]) / self.words\n",
    "        self.feature_table[33]=len(self.word_dict[\"VERB\"]) / self.words\n",
    "        self.feature_table[34]=len(self.word_dict[\"ADP\"]) / self.words\n",
    "        self.feature_table[35]=len(self.word_dict[\"DET\"]) / self.words\n",
    "        self.feature_table[36]=len(self.word_dict[\"NOUN\"]) / self.words\n",
    "        self.feature_table[37]=len(self.word_dict[\"ADJ\"]) / self.words\n",
    "        self.feature_table[38]=len(self.word_dict[\"PUNCT\"]) / self.words\n",
    "        self.feature_table[39]=len(self.word_dict[\"INTJ\"])/ self.words\n",
    "        self.feature_table[40]=len(self.word_dict[\"NUM\"]) / self.words\n",
    "        self.feature_table[41]=len(self.word_dict[\"PRON\"]) / self.words\n",
    "        self.feature_table[42]=len(self.word_dict[\"AUX\"]) / self.words\n",
    "        self.feature_table[43]=len(self.word_dict[\"CCONJ\"]) / self.words\n",
    "        self.feature_table[44]=len(self.word_dict[\"PART\"]) / self.words\n",
    "        self.feature_table[45]=len(self.word_dict[\"PROPN\"]) / self.words\n",
    "        self.feature_table[46]=len(self.word_dict[\"SCONJ\"]) / self.words\n",
    "        self.feature_table[47]=len(self.word_dict[\"CONJ\"]) / self.words\n",
    "        self.feature_table[48]=len(self.word_dict[\"PUNCT\"]) / self.words\n",
    "        self.feature_table[49]=len(self.word_dict[\"INTJ\"]) / self.words\n",
    "        self.feature_table[50], x = self.counting_lemma(line1)#20\n",
    "        self.feature_table[50] /= self.words\n",
    "        self.feature_table[51] = self.first_person_singular_verbs(line1) / self.words#23\n",
    "        self.feature_table[52] = self.mis_spell(line1)/self.words#24\n",
    "        self.feature_table[53], self.feature_table[54] = self.NES(line1)#25 26\n",
    "        self.feature_table[53] /= self.words\n",
    "        self.feature_table[54] /= self.words\n",
    "        self.feature_table[54] = self.neg_analyze(line1) / self.words#28\n",
    "        self.feature_table[55], self.feature_table[56] = self.content_function(line1)#29 30\n",
    "        self.feature_table[55] /= self.words\n",
    "        self.feature_table[56] /= self.words\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'output.txt'\n",
    "    NLP = NLP_features(file_path)\n",
    "    NLP.generate_features()\n",
    "    print(NLP.feature_table)\n",
    "\n",
    "# Sample output:\n",
    "# [6.37000000e+02 1.00000000e+00 2.90000000e+01 7.60000000e+01\n",
    "#  6.40000000e+01 7.60000000e+01 1.29000000e+02 2.90000000e+01\n",
    "#  1.30000000e+01 1.00000000e+00 8.00000000e+00 9.80000000e+01\n",
    "#  4.80000000e+01 1.90000000e+01 1.40000000e+01 2.20000000e+01\n",
    "#  1.00000000e+01 0.00000000e+00 1.30000000e+01 1.00000000e+00\n",
    "#  2.69000000e+02 3.80000000e+01 1.89000000e+02 1.60000000e+01\n",
    "#  1.30000000e+01 0.00000000e+00 1.90000000e+01 9.00000000e+00\n",
    "#  1.90000000e+01 2.89000000e+02 2.92000000e+02 1.56985871e-03\n",
    "#  4.55259027e-02 1.19309262e-01 1.00470958e-01 1.19309262e-01\n",
    "#  2.02511774e-01 4.55259027e-02 2.04081633e-02 1.56985871e-03\n",
    "#  1.25588697e-02 1.53846154e-01 7.53532182e-02 2.98273155e-02\n",
    "#  2.19780220e-02 3.45368917e-02 1.56985871e-02 0.00000000e+00\n",
    "#  2.04081633e-02 1.56985871e-03 4.22291994e-01 2.51177394e-02\n",
    "#  2.04081633e-02 0.00000000e+00 2.98273155e-02 4.53689168e-01\n",
    "#  4.58398744e-01]\n",
    "\n",
    "# The output is a bunch of numbers, the attributes of these numbers are shown below.\n",
    "# ['words_number', 'SPACE', 'ADV', 'VERB', \n",
    "#  'ADP', 'DET', 'NOUN', 'ADJ', \n",
    "#  'PUNCT', 'INTJ', 'NUM', 'PRON', \n",
    "#  'AUX', 'CCONJ', 'PART', 'PROPN', \n",
    "#  'SCONJ', 'CONJ', 'Punctuation', 'hestitation_word', \n",
    "#  'lemma_number', 'most_frequent', 'noun_chunk', 'person_singular_verbs', \n",
    "#  'misspell', 'time_spec', 'spec', 'sentence', \n",
    "#  'neg_word', 'content', 'function', 'SPACE_R', \n",
    "#  'ADV_R', 'VERB_R', 'ADP_R', 'DET_R', \n",
    "#  'NOUN_R', 'ADJ_R', 'PUNCT_R', 'INTJ_R', \n",
    "#  'NUM_R', 'PRON_R', 'AUX_R', 'CCONJ_R', \n",
    "#  'PART_R', 'PROPN_R', 'SCONJ_R', 'CONJ_R',\n",
    "#  'Punctuation_R', 'hestitation_word_R', 'lemma_number_R', 'person_singular_verbs_R', \n",
    "#  'misspell_R', 'time_spec_R', 'spec_R', 'neg_word_R', \n",
    "#  'content_R', 'function_R']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
