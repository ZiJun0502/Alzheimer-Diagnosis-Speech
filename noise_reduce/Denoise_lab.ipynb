{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zETVKp1Ffi7u"
      },
      "outputs": [],
      "source": [
        "!pip install librosa\n",
        "!pip install pysndfx\n",
        "!pip install python_speech_features\n",
        "!apt-get install sox\n",
        "!pip install PyWavelets\n",
        "!pip install pydub\n",
        "!pip install noisereduce\n",
        "!pip install webrtcvad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLf-Ahemf0SR",
        "outputId": "d75afa18-dab4-4a62-f255-df4e45619742"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "import pydub\n",
        "import noisereduce\n",
        "import pywt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "import math\n",
        "import scipy as sp\n",
        "from pysndfx import AudioEffectsChain\n",
        "import python_speech_features\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from pylab import rcParams\n",
        "from pydub import AudioSegment\n",
        "from noisereduce import reduce_noise\n",
        "import webrtcvad\n",
        "import wave\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ooivRVXtCES"
      },
      "source": [
        "# **SNR(Signal-to-noise ratio)**\n",
        "the standard to calculate the ac rate of denoise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDhmrdyHtQYs"
      },
      "outputs": [],
      "source": [
        "def calculate_snr(original_audio, denoised_audio):\n",
        "    # Ensure both audio signals have the same length\n",
        "    min_length = min(len(original_audio), len(denoised_audio))\n",
        "    original_audio = original_audio[:min_length]\n",
        "    denoised_audio = denoised_audio[:min_length]\n",
        "\n",
        "    # Calculate the power of the original audio\n",
        "    power_original = np.sum(np.square(original_audio))\n",
        "\n",
        "    # Calculate the power of the noise (residual after denoising)\n",
        "    noise = original_audio - denoised_audio\n",
        "    power_noise = np.sum(np.square(noise))\n",
        "\n",
        "    # Calculate SNR in decibels\n",
        "    snr = 10 * np.log10(power_original / power_noise)\n",
        "\n",
        "    return snr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLIedVFttTez"
      },
      "source": [
        "# **Load original audio**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHhmPwB3kTn8"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/F03.wav'\n",
        "y, sr = librosa.load(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "7XTRXuzIk7Vk",
        "outputId": "bf7d9243-6384-49a0-ecca-234e176d1e06"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "plt.title('Waveform of Original Audio')\n",
        "IPython.display.Audio(data=y, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "nWsp9WADSuOb",
        "outputId": "090c2a70-b2f6-4b8a-d137-745269656c01"
      },
      "outputs": [],
      "source": [
        "S1 = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64)\n",
        "D1 = librosa.power_to_db(S1, ref=np.max)\n",
        "librosa.display.specshow(D1, x_axis='time', y_axis='mel');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSLTQJpwSYYs"
      },
      "source": [
        "# **NR library denoise result**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE_Wbc4RSX1p"
      },
      "outputs": [],
      "source": [
        "source_file='/content/drive/MyDrive/F03.wav'\n",
        "#output_file='/content/drive/MyDrive/Colab Notebooks/term project/~noise CTT/'+str(i)+'CTT.wav'\n",
        "y, sr = librosa.load(file_path)\n",
        "y_reduced = reduce_noise(y,sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "-uf3rYVlUd1g",
        "outputId": "51b0218e-5e7f-4491-f7aa-1ff1379ff45d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "librosa.display.waveshow(y_reduced, sr=sr)\n",
        "IPython.display.Audio(data=y_reduced, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHfG6-Fwtmbf",
        "outputId": "474e70f8-5167-4eac-abf6-f39fe2609c45"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_reduced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wd0ysfvrmZB"
      },
      "source": [
        "# **Double NR implement**\n",
        "Using NR library twice, and obsevering its effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znxImk84rlxG"
      },
      "outputs": [],
      "source": [
        "y_reduced_twice = reduce_noise(y_reduced,sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "CPnw6mIzsDfh",
        "outputId": "bf521248-d3c7-41e6-dbfb-0cde8f0a828c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "librosa.display.waveshow(y_reduced, sr=sr)\n",
        "librosa.display.waveshow(y_reduced_twice, sr=sr)\n",
        "IPython.display.Audio(data=y_reduced_twice, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3YsQ9HQt7QA",
        "outputId": "a05f6251-716b-4946-9b3f-c36e8f75f4f8"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_reduced_twice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uClUpI5CyvGB"
      },
      "source": [
        "# **Tunning NR parameter**\n",
        "Keep adjusting and experimenting until you achieve the desired balance between noise reduction and preserving low-frequency voice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJQDkrOQy6_W"
      },
      "outputs": [],
      "source": [
        "y_reduced = reduce_noise(\n",
        "    y=y,sr=sr,\n",
        "    freq_mask_smooth_hz=1500,  # Experiment with different values\n",
        "    time_constant_s=2.0,  # Experiment with different values\n",
        "    thresh_n_mult_nonstationary=1,  # Experiment with different values\n",
        "    sigmoid_slope_nonstationary=10,  # Experiment with different values\n",
        "    prop_decrease=1  # Experiment with different values\n",
        ")\n",
        "y_reduced_mod = reduce_noise(\n",
        "    y=y_reduced,sr=sr,\n",
        "    freq_mask_smooth_hz=500,  # Experiment with different values\n",
        "    time_constant_s=1,  # Experiment with different values\n",
        "    thresh_n_mult_nonstationary=1.5,  # Experiment with different values\n",
        "    sigmoid_slope_nonstationary=5,  # Experiment with different values\n",
        "    prop_decrease=1  # Experiment with different values\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "Bb9zgV0gzAcm",
        "outputId": "5421ec78-f26c-4ae6-86e1-417c3555d59e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "#librosa.display.waveshow(y, sr=sr)\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "librosa.display.waveshow(y_reduced, sr=sr)\n",
        "librosa.display.waveshow(y_reduced_mod, sr=sr)\n",
        "#IPython.display.Audio(data=y_reduced, rate=22055)\n",
        "IPython.display.Audio(data=y_reduced_mod, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szi9OsPouHJF",
        "outputId": "caf9b52d-8f4d-4ee2-b66a-6eb1fa064556"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThIU7jWxuSWc",
        "outputId": "799e534e-bd09-4065-f8df-c6692395ab61"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_reduced_mod)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvqrQ4lhsvX5"
      },
      "source": [
        "# **Enhance Audio with double NR**\n",
        "with highshelf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1TO5NVgs3ac"
      },
      "outputs": [],
      "source": [
        "apply_audio_effects = AudioEffectsChain().highshelf(gain=10.0, frequency=10000, slope=0.1)\n",
        "y_enhanced = apply_audio_effects(y_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "aoXdV7fhs-um",
        "outputId": "2892d0a7-a179-4aa1-9d73-a228157161c4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y_enhanced, sr=sr)\n",
        "librosa.display.waveshow(y_reduced, sr=sr)\n",
        "IPython.display.Audio(data=y_enhanced, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40xJUhc8uaPJ",
        "outputId": "edb1bc5c-2350-49eb-e59b-45aa27bd6eb7"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_enhanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-zv4TcCvvG_"
      },
      "source": [
        "with lowshelf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY7Adlxrvufb"
      },
      "outputs": [],
      "source": [
        "apply_audio_effects = AudioEffectsChain().lowshelf(gain=10.0, frequency=10000, slope=0.1)\n",
        "y_enhanced = apply_audio_effects(y_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "pLDwX-AfwNuS",
        "outputId": "018c679c-c340-46f0-b4e4-1e1fff2d4251"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y_enhanced, sr=sr)\n",
        "librosa.display.waveshow(y_reduced, sr=sr)\n",
        "IPython.display.Audio(data=y_enhanced, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXU9WlKauzej",
        "outputId": "0ca69294-fdfd-4ff3-cb26-d89ce48e734d"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_enhanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-bBsruMSPuZ"
      },
      "source": [
        "# **Spectral subtraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP04rFSnSJGj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function for spectral subtraction\n",
        "def spectral_subtraction(y, noise_estimation_factor=1.5):\n",
        "    # Compute the spectrogram\n",
        "    spec = librosa.stft(y)\n",
        "\n",
        "    # Estimate the noise spectrum\n",
        "    noise = np.mean(np.abs(spec[:, :int(spec.shape[1] / 5)]), axis=1)\n",
        "\n",
        "    # Apply spectral subtraction\n",
        "    spec -= noise[:, np.newaxis] * noise_estimation_factor\n",
        "    spec = np.maximum(spec, 0)\n",
        "\n",
        "    # Inverse transform to obtain the denoised signal\n",
        "    y_denoised = librosa.istft(spec)\n",
        "\n",
        "    return y_denoised\n",
        "\n",
        "# Apply spectral subtraction for noise reduction\n",
        "y_denoised = spectral_subtraction(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "Lf9hqrmelJ0S",
        "outputId": "634b9535-3c77-4100-e807-2f29e7a7b9c9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 2)\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "librosa.display.waveshow(y_denoised, sr=sr)\n",
        "plt.title('Waveform of Audio')\n",
        "IPython.display.Audio(data=y_denoised, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJMeqlpKu9-E",
        "outputId": "f4547653-4945-4d74-93fb-bab676453f16"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_denoised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "JxxMX8MikqCM",
        "outputId": "5a221d7d-56d3-463d-d2a4-44cf70237223"
      },
      "outputs": [],
      "source": [
        "# Visualize the spectrogram of the denoised audio\n",
        "librosa.display.specshow(librosa.amplitude_to_db(librosa.stft(y_denoised), ref=np.max), y_axis='log', x_axis='time')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Spectrogram of the Denoised Audio')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6XHrs2mBLTP"
      },
      "source": [
        "# **Filtering low-frequencies**\n",
        "As we noticed, low frequencies does not contribute to bird sounds, a first idea is to remove these low frequencies. A high pass filter helps in this task. Reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lfilter.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "3S94WYOnnEXg",
        "outputId": "829bdd99-7dd2-4fea-ae36-fbd7fbbad5bf"
      },
      "outputs": [],
      "source": [
        "from scipy import signal\n",
        "import random\n",
        "\n",
        "def f_high(y,sr):\n",
        "    b,a = signal.butter(10, 2000/(sr/2), btype='highpass')\n",
        "    yf = signal.lfilter(b,a,y)\n",
        "    return yf\n",
        "yf = f_high(y, sr)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(yf,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=yf, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtzdugfGvIRh",
        "outputId": "25b1c9d9-fbb0-477f-d2ec-588a0bf0acc9"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, yf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "rIRxRUNepFZx",
        "outputId": "5285fb9d-d9fb-4331-a27c-34a5bb3c3c22"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=yf, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgiJyALjqeP3"
      },
      "source": [
        "# **PCEN**\n",
        "PCEN has become a very useful strategy for acoustic event detection, and it has shown to perform better in such tasks as a frontend. Its idea is to perform non-linear compression on time-frequency channels.\n",
        "\n",
        "I am using the example shown here: https://librosa.org/doc/latest/generated/librosa.pcen.html?highlight=pcen#librosa.pcen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "GRNO-qkNpWW8",
        "outputId": "9a232c89-02d9-41d3-e510-0a5155c91671"
      },
      "outputs": [],
      "source": [
        "Dp = librosa.pcen(S1 * (2**31), sr=sr, gain=1.1, hop_length=512, bias=2, power=0.5, time_constant=0.8, eps=1e-06, max_size=2)\n",
        "yp = librosa.feature.inverse.mel_to_audio(Dp)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time')\n",
        "librosa.display.waveshow(yp,sr=sr, axis='time')\n",
        "IPython.display.Audio(data=yp, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BOoUlb1vSi4",
        "outputId": "57a771f1-3a78-4744-f8c3-577d3966981d"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, yp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "19xTEHcVCeta",
        "outputId": "962fc409-654d-417d-f042-2dac43ed59d2"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=yp, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHJDQcaUqzwM"
      },
      "source": [
        "# **Spectral Gating**\n",
        "This is also a technique for noise reduction based on gates that monitor audio level. It is commonly used in music industry, and present in tools like Audacity (https://wiki.audacityteam.org/wiki/How_Audacity_Noise_Reduction_Works). I reproduced here the code made available by Tim Sainburg in his github (https://github.com/timsainb/noisereduce)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlCnVCVbqsyi"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import timedelta as td\n",
        "\n",
        "\n",
        "def _stft(y, n_fft, hop_length, win_length):\n",
        "    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
        "\n",
        "\n",
        "def _istft(y, hop_length, win_length):\n",
        "    return librosa.istft(y, hop_length=hop_length,win_length=win_length)\n",
        "\n",
        "\n",
        "def _amp_to_db(x):\n",
        "    return librosa.core.amplitude_to_db(x, ref=1.0, amin=1e-20, top_db=80.0)\n",
        "\n",
        "\n",
        "def _db_to_amp(x,):\n",
        "    return librosa.core.db_to_amplitude(x, ref=1.0)\n",
        "\n",
        "\n",
        "def plot_spectrogram(signal, title):\n",
        "    fig, ax = plt.subplots(figsize=(20, 4))\n",
        "    cax = ax.matshow(\n",
        "        signal,\n",
        "        origin=\"lower\",\n",
        "        aspect=\"auto\",\n",
        "        cmap=plt.cm.seismic,\n",
        "        vmin=-1 * np.max(np.abs(signal)),\n",
        "        vmax=np.max(np.abs(signal)),\n",
        "    )\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_statistics_and_filter(\n",
        "    mean_freq_noise, std_freq_noise, noise_thresh, smoothing_filter\n",
        "):\n",
        "    fig, ax = plt.subplots(ncols=2, figsize=(20, 4))\n",
        "    plt_mean, = ax[0].plot(mean_freq_noise, label=\"Mean power of noise\")\n",
        "    plt_std, = ax[0].plot(std_freq_noise, label=\"Std. power of noise\")\n",
        "    plt_std, = ax[0].plot(noise_thresh, label=\"Noise threshold (by frequency)\")\n",
        "    ax[0].set_title(\"Threshold for mask\")\n",
        "    ax[0].legend()\n",
        "    cax = ax[1].matshow(smoothing_filter, origin=\"lower\")\n",
        "    fig.colorbar(cax)\n",
        "    ax[1].set_title(\"Filter for smoothing Mask\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def removeNoise(\n",
        "    audio_clip,\n",
        "    noise_clip,\n",
        "    n_grad_freq=2,\n",
        "    n_grad_time=4,\n",
        "    n_fft=2048,\n",
        "    win_length=2048,\n",
        "    hop_length=512,\n",
        "    n_std_thresh=1.5,\n",
        "    prop_decrease=1.0,\n",
        "    verbose=False,\n",
        "    visual=False,\n",
        "):\n",
        "    \"\"\"Remove noise from audio based upon a clip containing only noise\n",
        "\n",
        "    Args:\n",
        "        audio_clip (array): The first parameter.\n",
        "        noise_clip (array): The second parameter.\n",
        "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
        "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
        "        n_fft (int): number audio of frames between STFT columns.\n",
        "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
        "        hop_length (int):number audio of frames between STFT columns.\n",
        "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
        "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
        "        visual (bool): Whether to plot the steps of the algorithm\n",
        "\n",
        "    Returns:\n",
        "        array: The recovered signal with noise subtracted\n",
        "\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        start = time.time()\n",
        "    # STFT over noise\n",
        "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
        "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # convert to dB\n",
        "    # Calculate statistics over noise\n",
        "    mean_freq_noise = np.mean(noise_stft_db, axis=1)\n",
        "    std_freq_noise = np.std(noise_stft_db, axis=1)\n",
        "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
        "    if verbose:\n",
        "        print(\"STFT on noise:\", td(seconds=time.time() - start))\n",
        "        start = time.time()\n",
        "    # STFT over signal\n",
        "    if verbose:\n",
        "        start = time.time()\n",
        "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
        "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
        "    if verbose:\n",
        "        print(\"STFT on signal:\", td(seconds=time.time() - start))\n",
        "        start = time.time()\n",
        "    # Calculate value to mask dB to\n",
        "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
        "    print(noise_thresh, mask_gain_dB)\n",
        "    # Create a smoothing filter for the mask in time and frequency\n",
        "    smoothing_filter = np.outer(\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_freq + 1, endpoint=False),\n",
        "                np.linspace(1, 0, n_grad_freq + 2),\n",
        "            ]\n",
        "        )[1:-1],\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_time + 1, endpoint=False),\n",
        "                np.linspace(1, 0, n_grad_time + 2),\n",
        "            ]\n",
        "        )[1:-1],\n",
        "    )\n",
        "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
        "    # calculate the threshold for each frequency/time bin\n",
        "    db_thresh = np.repeat(\n",
        "        np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
        "        np.shape(sig_stft_db)[1],\n",
        "        axis=0,\n",
        "    ).T\n",
        "    # mask if the signal is above the threshold\n",
        "    sig_mask = sig_stft_db < db_thresh\n",
        "    if verbose:\n",
        "        print(\"Masking:\", td(seconds=time.time() - start))\n",
        "        start = time.time()\n",
        "    # convolve the mask with a smoothing filter\n",
        "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
        "    sig_mask = sig_mask * prop_decrease\n",
        "    if verbose:\n",
        "        print(\"Mask convolution:\", td(seconds=time.time() - start))\n",
        "        start = time.time()\n",
        "    # mask the signal\n",
        "    sig_stft_db_masked = (\n",
        "        sig_stft_db * (1 - sig_mask)\n",
        "        + np.ones(np.shape(mask_gain_dB)) * mask_gain_dB * sig_mask\n",
        "    )  # mask real\n",
        "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
        "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (\n",
        "        1j * sig_imag_masked\n",
        "    )\n",
        "    if verbose:\n",
        "        print(\"Mask application:\", td(seconds=time.time() - start))\n",
        "        start = time.time()\n",
        "    # recover the signal\n",
        "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
        "    recovered_spec = _amp_to_db(\n",
        "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
        "    )\n",
        "    if verbose:\n",
        "        print(\"Signal recovery:\", td(seconds=time.time() - start))\n",
        "    if visual:\n",
        "        plot_spectrogram(noise_stft_db, title=\"Noise\")\n",
        "    if visual:\n",
        "        plot_statistics_and_filter(\n",
        "            mean_freq_noise, std_freq_noise, noise_thresh, smoothing_filter\n",
        "        )\n",
        "    if visual:\n",
        "        plot_spectrogram(sig_stft_db, title=\"Signal\")\n",
        "    if visual:\n",
        "        plot_spectrogram(sig_mask, title=\"Mask applied\")\n",
        "    if visual:\n",
        "        plot_spectrogram(sig_stft_db_masked, title=\"Masked signal\")\n",
        "    if visual:\n",
        "        plot_spectrogram(recovered_spec, title=\"Recovered spectrogram\")\n",
        "    return recovered_signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "Lzhdx72DrN_t",
        "outputId": "58b01648-52d0-42d4-c374-0ac7819ba57b"
      },
      "outputs": [],
      "source": [
        "noise1 = y[5*sr:6*sr]\n",
        "yg = removeNoise(audio_clip=y, noise_clip=noise1,\n",
        "    n_grad_freq=2,\n",
        "    n_grad_time=4,\n",
        "    n_fft=2048,\n",
        "    win_length=2048,\n",
        "    hop_length=512,\n",
        "    n_std_thresh=1.5,\n",
        "    prop_decrease=1.0,\n",
        "    verbose=False,\n",
        "    visual=False)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(yg,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=yg, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oElIMJ1TwNut",
        "outputId": "8ad20f3b-e4d2-4fcd-d0cf-3470ebbedb8c"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, yg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "wIUFsoiRC8KX",
        "outputId": "5016d897-1ccc-42e6-b89c-91a67e20f92a"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=yg, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWZmLIZGG0An"
      },
      "source": [
        "# **POWER DENOISE**\n",
        "receives an audio matrix, returns the matrix after gain reduction on noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V46kb7FxHFJi"
      },
      "outputs": [],
      "source": [
        "cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "threshold_h = round(np.median(cent))*1.5\n",
        "threshold_l = round(np.median(cent))*0.1\n",
        "less_noise = AudioEffectsChain().lowshelf(gain=-30.0, frequency=threshold_l, slope=0.8).highshelf(gain=-12.0, frequency=threshold_h, slope=0.5)#.limiter(gain=6.0)\n",
        "y_clean = less_noise(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "qpdCGuWSIOoi",
        "outputId": "4f7e225c-febb-41b5-d1ec-efbf97a1745e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y_clean,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_clean, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQnM6r3wwUAN",
        "outputId": "eb740635-a59b-4df3-f5be-642b572c0035"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "yeUaxi7JIWLu",
        "outputId": "10e9efc9-dd7e-425b-eb63-116b969d77ce"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=y_clean, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqn7WJwrIixv"
      },
      "source": [
        "# **Centroid denoise**\n",
        "receives an audio matrix,\n",
        "returns the matrix after gain reduction on noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47_3iR0II18r"
      },
      "outputs": [],
      "source": [
        "cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "threshold_h = np.max(cent)\n",
        "threshold_l = np.min(cent)\n",
        "less_noise = AudioEffectsChain().lowshelf(gain=-12.0, frequency=threshold_l, slope=0.5).highshelf(gain=-12.0, frequency=threshold_h, slope=0.5).limiter(gain=6.0)\n",
        "y_cleaned = less_noise(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "PNevC0YkI_sC",
        "outputId": "b20bafa7-7f90-4e0f-c569-4edcee0207d1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y_cleaned,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_cleaned, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlOMAFa-wclo",
        "outputId": "b095c809-a4ac-4e39-fd73-3d8c3b2b2f53"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "nJN2q9Q5JH-_",
        "outputId": "7339fb04-e17a-4c6b-b69c-231c43fb49ac"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=y_cleaned, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFfHmEk5JcoF"
      },
      "outputs": [],
      "source": [
        "cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "threshold_h = np.max(cent)\n",
        "threshold_l = np.min(cent)\n",
        "less_noise = AudioEffectsChain().lowshelf(gain=-30.0, frequency=threshold_l, slope=0.5).highshelf(gain=-30.0, frequency=threshold_h, slope=0.5).limiter(gain=10.0)\n",
        "# less_noise = AudioEffectsChain().lowpass(frequency=threshold_h).highpass(frequency=threshold_l)\n",
        "y_cleaned = less_noise(y)\n",
        "cent_cleaned = librosa.feature.spectral_centroid(y=y_cleaned, sr=sr)\n",
        "columns, rows = cent_cleaned.shape\n",
        "boost_h = math.floor(rows/3*2)\n",
        "boost_l = math.floor(rows/6)\n",
        "boost = math.floor(rows/3)\n",
        "# boost_bass = AudioEffectsChain().lowshelf(gain=20.0, frequency=boost, slope=0.8)\n",
        "boost_bass = AudioEffectsChain().lowshelf(gain=16.0, frequency=boost_h, slope=0.5)#.lowshelf(gain=-20.0, frequency=boost_l, slope=0.8)\n",
        "y_clean_boosted = boost_bass(y_cleaned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "YuTCHC3ZJqlB",
        "outputId": "216506a2-07ac-4091-d1c9-ffce26cea193"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y_clean_boosted,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_clean_boosted, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYxV7jCqwldD",
        "outputId": "ce2d8e63-cfd6-4d87-b286-962c6e9c7d61"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_clean_boosted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "svxwhhPlJyx5",
        "outputId": "c9ae4c31-0ad4-46ce-e6f8-6100d32825a6"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=y_clean_boosted, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTdIFvAgJMI3"
      },
      "source": [
        "# **MFCC Denoise**\n",
        "receives an audio matrix,\n",
        "    returns the matrix after gain reduction on noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF1eE4CxKH7T"
      },
      "outputs": [],
      "source": [
        "#mfcc_down\n",
        "hop_length = 512\n",
        "mfcc = python_speech_features.base.mfcc(y)\n",
        "mfcc = python_speech_features.base.logfbank(y)\n",
        "mfcc = python_speech_features.base.lifter(mfcc)\n",
        "sum_of_squares = []\n",
        "index = -1\n",
        "for r in mfcc:\n",
        "    sum_of_squares.append(0)\n",
        "    index = index + 1\n",
        "    for n in r:\n",
        "        sum_of_squares[index] = sum_of_squares[index] + n**2\n",
        "\n",
        "strongest_frame = sum_of_squares.index(max(sum_of_squares))\n",
        "hz = python_speech_features.base.mel2hz(mfcc[strongest_frame])\n",
        "max_hz = max(hz)\n",
        "min_hz = min(hz)\n",
        "speech_booster = AudioEffectsChain().highshelf(frequency=min_hz*(-1)*1.2, gain=-12.0, slope=0.6).limiter(gain=8.0)\n",
        "y_speach_boosted = speech_booster(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "ShmbmECCKhi_",
        "outputId": "ae43f9a1-6fe8-4b36-dff0-f669db7c4332"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y_speach_boosted,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_speach_boosted, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PdvcDfYwxrE",
        "outputId": "ae1759ba-a4bd-4ad6-85fc-c9da3f8caa20"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_speach_boosted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "Au5deHc0Kprv",
        "outputId": "59ac74f9-360d-4225-c33f-fb109fdb91d0"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=y_speach_boosted, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L61P2NeyK9wO"
      },
      "outputs": [],
      "source": [
        "#mfcc_up\n",
        "hop_length = 512\n",
        "mfcc = python_speech_features.base.mfcc(y)\n",
        "mfcc = python_speech_features.base.logfbank(y)\n",
        "mfcc = python_speech_features.base.lifter(mfcc)\n",
        "sum_of_squares = []\n",
        "index = -1\n",
        "for r in mfcc:\n",
        "    sum_of_squares.append(0)\n",
        "    index = index + 1\n",
        "    for n in r:\n",
        "        sum_of_squares[index] = sum_of_squares[index] + n**2\n",
        "strongest_frame = sum_of_squares.index(max(sum_of_squares))\n",
        "hz = python_speech_features.base.mel2hz(mfcc[strongest_frame])\n",
        "max_hz = max(hz)\n",
        "min_hz = min(hz)\n",
        "speech_booster = AudioEffectsChain().lowshelf(frequency=min_hz*(-1), gain=12.0, slope=0.5)#.highshelf(frequency=min_hz*(-1)*1.2, gain=-12.0, slope=0.5)#.limiter(gain=8.0)\n",
        "y_speach_boosted = speech_booster(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "s83ZksAQLPEm",
        "outputId": "56396876-a0d1-463a-98d3-c687f2e1bf1a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y_speach_boosted,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_speach_boosted, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZqhLydOw6N6",
        "outputId": "145f40dc-a445-4f09-b387-b9d96619babb"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_speach_boosted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "PvL2CQdfLw5q",
        "outputId": "192696e0-5fad-493c-89a2-5070c07f3180"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=y_speach_boosted, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zocM8kKYLZGk"
      },
      "source": [
        "# **Median Denoise**\n",
        "receives an audio matrix,\n",
        "    returns the matrix after gain reduction on noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hipCuVrMLoCk"
      },
      "outputs": [],
      "source": [
        "mod_y = sp.signal.medfilt(y,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "MHX1UctRL3LJ",
        "outputId": "276a89e9-101c-4745-e72f-5d52bbfcce62"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(mod_y,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=mod_y, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDDQO-h4xASX",
        "outputId": "25e535ba-4200-410d-c819-dbe1671a9e59"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, mod_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "7-Txua3AMBW2",
        "outputId": "f0b100e1-fcf2-40cc-97bc-a8593c0a32b4"
      },
      "outputs": [],
      "source": [
        "Sf1 = librosa.feature.melspectrogram(y=mod_y, sr=sr, n_mels=64)\n",
        "Df1 = librosa.power_to_db(Sf1, ref=np.max)\n",
        "librosa.display.specshow(Df1, x_axis='time', y_axis='mel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BObLoGisMHlC"
      },
      "source": [
        "# **SILENCE TRIMMER**\n",
        "receives an audio matrix,\n",
        "    returns an audio matrix with less silence and the amout of time that was trimmed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Fe7DM0RMPkQ"
      },
      "outputs": [],
      "source": [
        "y_trimmed, index = librosa.effects.trim(y, top_db=20, frame_length=2, hop_length=500)\n",
        "#trimmed_length = librosa.get_duration(y) - librosa.get_duration(y_trimmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "uGejrwZVMXZQ",
        "outputId": "a09f9751-0b14-4c78-efde-2bddbb57b1e3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y_trimmed,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_trimmed, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocpAZDFqxJ2E",
        "outputId": "e1e04698-3936-43a6-fa75-0edd5e1be751"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_trimmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m10dojuIPinT"
      },
      "source": [
        "# **AUDIO ENHANCER**\n",
        "receives an audio matrix,\n",
        "    returns the same matrix after audio manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVez_p37PaUa"
      },
      "outputs": [],
      "source": [
        "apply_audio_effects = AudioEffectsChain().lowshelf(gain=10.0, frequency=260, slope=0.1).reverb(reverberance=25, hf_damping=5, room_scale=5, stereo_depth=50, pre_delay=20, wet_gain=0, wet_only=False)#.normalize()\n",
        "y_enhanced = apply_audio_effects(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "1TzkbsbyPrWp",
        "outputId": "d6b78ed6-0446-4d53-af59-64474f12535c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y_enhanced,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_enhanced, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws-4ABByxRxs",
        "outputId": "75af6038-a0e5-4225-a60b-e6f292dc9787"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_enhanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKhmup6zP4FO"
      },
      "source": [
        "# **Wavelet Denoise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtLpRXIeQVXq"
      },
      "outputs": [],
      "source": [
        "wavelet = 'db1'  # Daubechies wavelet with 1 vanishing moment (change as needed)\n",
        "level = 4  # Adjust the level of decomposition (change as needed)\n",
        "coeffs = pywt.wavedec(y, wavelet, level=level)\n",
        "threshold = 0.3  # Adjust the threshold value (change as needed)\n",
        "coeffs_thresholded = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n",
        "y_wavelets = pywt.waverec(coeffs_thresholded, wavelet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "I2xWrvIXRW79",
        "outputId": "96ee614b-5fe7-4a66-ca88-908456d8f996"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y_wavelets,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_wavelets, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4JjdPLlxd4h",
        "outputId": "88e20c31-4d0d-4648-9eec-421e79851b1d"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_wavelets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9ozZDsklUPe"
      },
      "outputs": [],
      "source": [
        "wavelet = 'sym8'  # Daubechies wavelet with 1 vanishing moment (change as needed)\n",
        "level = 5  # Adjust the level of decomposition (change as needed)\n",
        "coeffs = pywt.wavedec(y, wavelet, level=level)\n",
        "threshold = 0.3  # Adjust the threshold value (change as needed)\n",
        "coeffs_thresholded = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n",
        "y_wavelets = pywt.waverec(coeffs_thresholded, wavelet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "CDLJuL_JlvGX",
        "outputId": "241887e2-6b16-436e-97c7-11f7aeda9f45"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "librosa.display.waveshow(y,sr=sr, axis='time');\n",
        "librosa.display.waveshow(y_wavelets,sr=sr, axis='time');\n",
        "IPython.display.Audio(data=y_wavelets, rate=22055)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1jVJAd8xj6y",
        "outputId": "0f32a5b5-f016-40f8-a3ac-e242b59bbed9"
      },
      "outputs": [],
      "source": [
        "calculate_snr(y, y_wavelets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm5CA2GOVp40"
      },
      "source": [
        "# **webrtcvad**\n",
        "VAD denoise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayofmWVYP4J-"
      },
      "outputs": [],
      "source": [
        "def plot_waveforms(original_audio, denoised_audio, sample_rate, title=\"Waveform Comparison\"):\n",
        "    # Convert to raw numpy arrays\n",
        "    original_samples = np.array(original_audio.get_array_of_samples())\n",
        "    denoised_samples = np.array(denoised_audio.get_array_of_samples())\n",
        "\n",
        "    # Make sure both arrays have the same length\n",
        "    min_length = min(len(original_samples), len(denoised_samples))\n",
        "    original_samples = original_samples[:min_length]\n",
        "    denoised_samples = denoised_samples[:min_length]\n",
        "\n",
        "    # Time axis\n",
        "    time = np.arange(0, min_length) / sample_rate\n",
        "\n",
        "    # Plot original waveform\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(time, original_samples, label='Original')\n",
        "    #plt.title('Original Waveform')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot denoised waveform\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(time, denoised_samples, label='Denoised', color='orange')\n",
        "    plt.title('Denoised Waveform')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "    display(Audio(denoised_samples, rate=sample_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "iyUCShGeWAlC",
        "outputId": "c77a002b-aabf-4df3-967f-9230aa39a43d"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import contextlib\n",
        "import sys\n",
        "import wave\n",
        "import webrtcvad\n",
        "\n",
        "\n",
        "def read_wave(path):\n",
        "    \"\"\"Reads a .wav file.\n",
        "\n",
        "    Takes the path, and returns (PCM audio data, sample rate).\n",
        "    \"\"\"\n",
        "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "        num_channels = wf.getnchannels()\n",
        "        assert num_channels == 1\n",
        "        sample_width = wf.getsampwidth()\n",
        "        assert sample_width == 2\n",
        "        sample_rate = wf.getframerate()\n",
        "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "        pcm_data = wf.readframes(wf.getnframes())\n",
        "        return pcm_data, sample_rate\n",
        "\n",
        "\n",
        "def write_wave(path, audio, sample_rate):\n",
        "    \"\"\"Writes a .wav file.\n",
        "\n",
        "    Takes path, PCM audio data, and sample rate.\n",
        "    \"\"\"\n",
        "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
        "        wf.setnchannels(1)\n",
        "        wf.setsampwidth(2)\n",
        "        wf.setframerate(sample_rate)\n",
        "        wf.writeframes(audio)\n",
        "\n",
        "\n",
        "class Frame(object):\n",
        "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
        "    def __init__(self, bytes, timestamp, duration):\n",
        "        self.bytes = bytes\n",
        "        self.timestamp = timestamp\n",
        "        self.duration = duration\n",
        "\n",
        "\n",
        "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "    \"\"\"Generates audio frames from PCM audio data.\n",
        "\n",
        "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
        "    the sample rate.\n",
        "\n",
        "    Yields Frames of the requested duration.\n",
        "    \"\"\"\n",
        "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "    offset = 0\n",
        "    timestamp = 0.0\n",
        "    duration = (float(n) / sample_rate) / 2.0\n",
        "    while offset + n < len(audio):\n",
        "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "        timestamp += duration\n",
        "        offset += n\n",
        "\n",
        "\n",
        "def vad_collector(sample_rate, frame_duration_ms,\n",
        "                  padding_duration_ms, vad, frames):\n",
        "    \"\"\"Filters out non-voiced audio frames.\n",
        "\n",
        "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
        "    the voiced audio.\n",
        "\n",
        "    Uses a padded, sliding window algorithm over the audio frames.\n",
        "    When more than 90% of the frames in the window are voiced (as\n",
        "    reported by the VAD), the collector triggers and begins yielding\n",
        "    audio frames. Then the collector waits until 90% of the frames in\n",
        "    the window are unvoiced to detrigger.\n",
        "\n",
        "    The window is padded at the front and back to provide a small\n",
        "    amount of silence or the beginnings/endings of speech around the\n",
        "    voiced frames.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "    sample_rate - The audio sample rate, in Hz.\n",
        "    frame_duration_ms - The frame duration in milliseconds.\n",
        "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
        "    vad - An instance of webrtcvad.Vad.\n",
        "    frames - a source of audio frames (sequence or generator).\n",
        "\n",
        "    Returns: A generator that yields PCM audio data.\n",
        "    \"\"\"\n",
        "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
        "    # We use a deque for our sliding window/ring buffer.\n",
        "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
        "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
        "    # NOTTRIGGERED state.\n",
        "    triggered = False\n",
        "\n",
        "    voiced_frames = []\n",
        "    for frame in frames:\n",
        "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
        "\n",
        "        sys.stdout.write('1' if is_speech else '0')\n",
        "        if not triggered:\n",
        "            ring_buffer.append((frame, is_speech))\n",
        "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
        "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
        "            # the ring buffer are voiced frames, then enter the\n",
        "            # TRIGGERED state.\n",
        "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
        "                triggered = True\n",
        "                sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
        "                # We want to yield all the audio we see from now until\n",
        "                # we are NOTTRIGGERED, but we have to start with the\n",
        "                # audio that's already in the ring buffer.\n",
        "                for f, s in ring_buffer:\n",
        "                    voiced_frames.append(f)\n",
        "                ring_buffer.clear()\n",
        "        else:\n",
        "            # We're in the TRIGGERED state, so collect the audio data\n",
        "            # and add it to the ring buffer.\n",
        "            voiced_frames.append(frame)\n",
        "            ring_buffer.append((frame, is_speech))\n",
        "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
        "            # If more than 90% of the frames in the ring buffer are\n",
        "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
        "            # audio we've collected.\n",
        "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
        "                sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "                triggered = False\n",
        "                yield b''.join([f.bytes for f in voiced_frames])\n",
        "                ring_buffer.clear()\n",
        "                voiced_frames = []\n",
        "    if triggered:\n",
        "        sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "    sys.stdout.write('\\n')\n",
        "    # If we have any leftover voiced audio when we run out of input,\n",
        "    # yield it.\n",
        "    if voiced_frames:\n",
        "        yield b''.join([f.bytes for f in voiced_frames])\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    if len(args) != 2:\n",
        "        sys.stderr.write(\n",
        "            'Usage: example.py 3 /content/drive/MyDrive/F03.wav \\n')\n",
        "        sys.exit(1)\n",
        "    audio, sample_rate = read_wave(args[1])\n",
        "    vad = webrtcvad.Vad(int(args[0]))\n",
        "    frames = frame_generator(30, audio, sample_rate)\n",
        "    frames = list(frames)\n",
        "    segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
        "    for i, segment in enumerate(segments):\n",
        "        path = 'chunk-%002d.wav' % (i,)\n",
        "        print(' Writing %s' % (path,))\n",
        "        write_wave(path, segment, sample_rate)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(sys.argv[1:])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
