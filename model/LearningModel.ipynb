{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj1CqCW738eI"
      },
      "source": [
        "## Connect Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X6g6His2_u9",
        "outputId": "d893175f-fe90-46be-ad63-8f95738fe97a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVPjZBxJ3_s5"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH-x2tjK37Ua"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZcuDc_76KMZ"
      },
      "source": [
        "## Read and split training file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3A3bE1O6J2k",
        "outputId": "e13cdd16-5202-44dc-fbcd-27e48afce24f"
      },
      "outputs": [],
      "source": [
        "whole_dataset = \"/content/drive/MyDrive/term project/final_training_data/merged_data.csv\"\n",
        "normalized_dataset = \"/content/drive/MyDrive/term project/final_training_data/normalized_merged_data.csv\"\n",
        "MCI_dataset = \"/content/drive/MyDrive/term project/final_training_data/MCI_data.csv\"\n",
        "MCI_AD = \"/content/drive/MyDrive/term project/final_training_data/MCI_patient.csv\"\n",
        "modified_result = \"/content/drive/MyDrive/term project/final_training_data/modified_result.csv\" # 12/22\n",
        "training_df = pd.read_csv(MCI_AD)\n",
        "\n",
        "X = training_df.drop(['name', 'AD_diagnose'] , axis=1)\n",
        "y = training_df['AD_diagnose']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=20)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPy7QJ4nSvwU",
        "outputId": "959df39b-9d0b-49d9-c72e-d05937c1d907"
      },
      "outputs": [],
      "source": [
        "MCI_AD = \"/content/drive/MyDrive/term project/final_training_data/modified_result.csv\"\n",
        "training_df = pd.read_csv(MCI_AD)\n",
        "print(list(training_df.keys()))\n",
        "print()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEZ01SU-F2UB",
        "outputId": "0f9549f9-04d0-47c2-8a58-e5d9a53d87c0"
      },
      "outputs": [],
      "source": [
        "# Zeros = [\"_\" for i in range(y_train.shape[0]) if y[i] == 0]  # Normal people\n",
        "Ones = [\"_\" for i in range(y_train.shape[0]) if y[i] == 1]  # AD people\n",
        "Twos = [\"_\" for i in range(y_train.shape[0]) if y[i] == 2]  # MCI people\n",
        "print(len(Ones), len(Twos))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FfzqT5tUDbw"
      },
      "source": [
        "## Lasso feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knxdCcIwUHSF",
        "outputId": "f59fbce1-18e7-4a60-fe72-f750d522acea"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (important for Lasso regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create a Lasso regression model\n",
        "lasso_model = Lasso(alpha=0.005)  # Adjust alpha for stronger/weaker regularization\n",
        "\n",
        "# Fit the model to the training data\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# Print the coefficients of the model\n",
        "print(\"Coefficients:\", lasso_model.coef_.shape)\n",
        "print(\"Coefficients:\", lasso_model.coef_)\n",
        "\n",
        "not_zero = 0\n",
        "for i in lasso_model.coef_:\n",
        "    if i != 0:\n",
        "        not_zero += 1\n",
        "print(\"not_zero\", not_zero)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "ncxMbqLAVdJE",
        "outputId": "40b5c363-61f5-4c75-965d-9d51e786ac14"
      },
      "outputs": [],
      "source": [
        "# Drop features with coeff 0\n",
        "for i in range(len(lasso_model.coef_)-1, -1, -1):\n",
        "    if lasso_model.coef_[i] == 0:\n",
        "        training_df.drop(training_df.columns[i], axis = 1, inplace =True)\n",
        "# for i in range(59, -1, -1):\n",
        "#     if lasso_model.coef_[i] == 0:\n",
        "#         training_df.drop(training_df.columns[i], axis = 1, inplace =True)\n",
        "print(training_df.columns)\n",
        "\n",
        "X = training_df.drop(['name', 'AD_diagnose'] , axis=1)\n",
        "y = training_df['AD_diagnose']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "training_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4WosQRrW65a"
      },
      "source": [
        "# Build model\n",
        "## K nearest neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuGJ6BPBW6uJ",
        "outputId": "df3c0144-0146-4f4f-82d0-de86fb36ef3e"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(10) # Define classifier\n",
        "knn.fit(X_train, y_train) # Train model\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = knn.predict(X_train)\n",
        "y_test_pred = knn.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "knn_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "knn_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "knn_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "knn_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "knn_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "knn_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % knn_train_accuracy)\n",
        "print('- MCC: %s' % knn_train_mcc)\n",
        "print('- F1 score: %s' % knn_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % knn_test_accuracy)\n",
        "print('- MCC: %s' % knn_test_mcc)\n",
        "print('- F1 score: %s' % knn_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxnB5kutZKEh"
      },
      "source": [
        "## Support Vector Machine (rbf kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjz6N-mRZKPL",
        "outputId": "a1b4ff6e-4788-46f9-f9df-fc437a28eb86"
      },
      "outputs": [],
      "source": [
        "svm_rbf = SVC()\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = svm_rbf.predict(X_train)\n",
        "y_test_pred = svm_rbf.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "svm_rbf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "svm_rbf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "svm_rbf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "svm_rbf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "svm_rbf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "svm_rbf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % svm_rbf_train_accuracy)\n",
        "print('- MCC: %s' % svm_rbf_train_mcc)\n",
        "print('- F1 score: %s' % svm_rbf_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % svm_rbf_test_accuracy)\n",
        "print('- MCC: %s' % svm_rbf_test_mcc)\n",
        "print('- F1 score: %s' % svm_rbf_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRvM2gDnad6W"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiF86CwMahNc",
        "outputId": "249d8fd1-5a25-44fe-f6c9-7b45e6776bd3"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier(max_depth=2) # Define classifier\n",
        "dt.fit(X_train, y_train) # Train model\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = dt.predict(X_train)\n",
        "y_test_pred = dt.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "dt_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "dt_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "dt_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "dt_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "dt_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "dt_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % dt_train_accuracy)\n",
        "print('- MCC: %s' % dt_train_mcc)\n",
        "print('- F1 score: %s' % dt_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % dt_test_accuracy)\n",
        "print('- MCC: %s' % dt_test_mcc)\n",
        "print('- F1 score: %s' % dt_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi-jslV4awyR"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKpgHCJVawiI",
        "outputId": "8c55eee2-7140-4726-ddc2-57430723ce46"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=25, max_samples = 40) # Define classifier\n",
        "rf.fit(X_train, y_train) # Train model\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = rf.predict(X_train)\n",
        "y_test_pred = rf.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "rf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "rf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "rf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "rf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "rf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "rf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % rf_train_accuracy)\n",
        "print('- MCC: %s' % rf_train_mcc)\n",
        "print('- F1 score: %s' % rf_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % rf_test_accuracy)\n",
        "print('- MCC: %s' % rf_test_mcc)\n",
        "print('- F1 score: %s' % rf_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCnbhxoPa6Nq"
      },
      "source": [
        "## Neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLx4HMIXa7GY",
        "outputId": "dfdf36be-182d-49f7-f4d2-60786602ff14"
      },
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(alpha=0.001, max_iter=10000)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = mlp.predict(X_train)\n",
        "y_test_pred = mlp.predict(X_test)\n",
        "\n",
        "# Training set performance\n",
        "mlp_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "mlp_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "mlp_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "mlp_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "mlp_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "mlp_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % mlp_train_accuracy)\n",
        "print('- MCC: %s' % mlp_train_mcc)\n",
        "print('- F1 score: %s' % mlp_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % mlp_test_accuracy)\n",
        "print('- MCC: %s' % mlp_test_mcc)\n",
        "print('- F1 score: %s' % mlp_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hqLL1oF5Vip"
      },
      "source": [
        "## Stack Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo-A1Ge35VWJ",
        "outputId": "f03b0131-e7c6-4632-a88e-4040b90fcec6"
      },
      "outputs": [],
      "source": [
        "estimator_list = [\n",
        "    ('knn',knn),\n",
        "    ('svm_rbf',svm_rbf),\n",
        "    ('dt',dt),\n",
        "    ('rf',rf),\n",
        "    ('mlp',mlp) ]\n",
        "\n",
        "# Build stack model\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimator_list, final_estimator=LogisticRegression()\n",
        ")\n",
        "\n",
        "# Train stacked model\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = stack_model.predict(X_train)\n",
        "y_test_pred = stack_model.predict(X_test)\n",
        "\n",
        "# Training set model performance\n",
        "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set model performance\n",
        "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
        "print('- MCC: %s' % stack_model_train_mcc)\n",
        "print('- F1 score: %s' % stack_model_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
        "print('- MCC: %s' % stack_model_test_mcc)\n",
        "print('- F1 score: %s' % stack_model_test_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq9tv5U7b-9s"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "a78xRyQGcHZ2",
        "outputId": "c58ca727-aa55-42ad-c992-4e9463b2e15a"
      },
      "outputs": [],
      "source": [
        "acc_test_list = {'knn':knn_test_accuracy,\n",
        "'svm_rbf': svm_rbf_test_accuracy,\n",
        "'dt': dt_test_accuracy,\n",
        "'rf': rf_test_accuracy,\n",
        "'mlp': mlp_test_accuracy,\n",
        "'stack': stack_model_test_accuracy}\n",
        "\n",
        "mcc_test_list = {'knn':knn_test_mcc,\n",
        "'svm_rbf': svm_rbf_test_mcc,\n",
        "'dt': dt_test_mcc,\n",
        "'rf': rf_test_mcc,\n",
        "'mlp': mlp_test_mcc,\n",
        "'stack': stack_model_test_mcc}\n",
        "\n",
        "f1_test_list = {'knn':knn_test_f1,\n",
        "'svm_rbf': svm_rbf_test_f1,\n",
        "'dt': dt_test_f1,\n",
        "'rf': rf_test_f1,\n",
        "'mlp': mlp_test_f1,\n",
        "'stack': stack_model_test_f1}\n",
        "\n",
        "acc_df = pd.DataFrame.from_dict(acc_test_list, orient='index', columns=['Accuracy'])\n",
        "mcc_df = pd.DataFrame.from_dict(mcc_test_list, orient='index', columns=['MCC'])\n",
        "f1_df = pd.DataFrame.from_dict(f1_test_list, orient='index', columns=['F1'])\n",
        "df = pd.concat([acc_df, mcc_df, f1_df], axis=1)\n",
        "df.plot(kind = \"line\")\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
